<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>KVM 虚拟机的存储与网络总结 - Shiori&#39;s Blog</title><meta name="Description" content="总结 KVM 虚拟机使用存储与网络的方式"><meta property="og:title" content="KVM 虚拟机的存储与网络总结" />
<meta property="og:description" content="总结 KVM 虚拟机使用存储与网络的方式" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://KanShiori.github.io/posts/cloud/vm/kvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E5%AD%98%E5%82%A8%E4%B8%8E%E7%BD%91%E7%BB%9C/" /><meta property="og:image" content="https://KanShiori.github.io/icons/favicon-16x16.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-11-28T17:29:39+08:00" />
<meta property="article:modified_time" content="2020-11-28T17:29:39+08:00" /><meta property="og:site_name" content="My cool site" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://KanShiori.github.io/icons/favicon-16x16.png"/>

<meta name="twitter:title" content="KVM 虚拟机的存储与网络总结"/>
<meta name="twitter:description" content="总结 KVM 虚拟机使用存储与网络的方式"/>
<meta name="application-name" content="Shiori&#39;s Blog">
<meta name="apple-mobile-web-app-title" content="Shiori&#39;s Blog"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="icon" href="/icons/favicon.ico"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://KanShiori.github.io/posts/cloud/vm/kvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E5%AD%98%E5%82%A8%E4%B8%8E%E7%BD%91%E7%BB%9C/" /><link rel="prev" href="https://KanShiori.github.io/posts/cloud/cloud_native/docker/how_docker_work/container-start-stop-summary/" /><link rel="next" href="https://KanShiori.github.io/posts/language/golang/language/memory-manager/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css"></noscript><link rel="preload" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "KVM 虚拟机的存储与网络总结",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/KanShiori.github.io\/posts\/cloud\/vm\/kvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E5%AD%98%E5%82%A8%E4%B8%8E%E7%BD%91%E7%BB%9C\/"
        },"image": ["https:\/\/KanShiori.github.io\/images\/Apple-Devices-Preview.png"],"genre": "posts","keywords": "虚拟机, KVM, 云计算","wordcount":  6866 ,
        "url": "https:\/\/KanShiori.github.io\/posts\/cloud\/vm\/kvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E5%AD%98%E5%82%A8%E4%B8%8E%E7%BD%91%E7%BB%9C\/","datePublished": "2020-11-28T17:29:39+08:00","dateModified": "2020-11-28T17:29:39+08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
            "@type": "Organization",
            "name": "xxxx","logo": "https:\/\/KanShiori.github.io\/images\/avatar.png"},"author": {
                "@type": "Person",
                "name": "Shiori"
            },"description": "总结 KVM 虚拟机使用存储与网络的方式"
    }
    </script></head>
    <body data-header-desktop="fixed" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Shiori&#39;s Blog"><img
        class="lazyload logo"
        src="/svg/loading.min.svg"
        data-src="/icons/favicon-32x32.png"
        data-srcset="/icons/favicon-32x32.png, /icons/favicon-32x32.png 1.5x, /icons/favicon-32x32.png 2x"
        data-sizes="auto"
        alt="/icons/favicon-32x32.png"
        title="/icons/favicon-32x32.png" />Shiori&#39;s Blog</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="http://kanshiori.cn" rel="noopener noreffer" target="_blank"> 主页 </a><a class="menu-item" href="/posts/"> 所有文章 </a><a class="menu-item" href="/tags/"> 标签 </a><a class="menu-item" href="/categories/"> 分类 </a><a class="menu-item" href="/about/"> 关于 </a><a class="menu-item" href="https://github.com/KanShiori/KanShiori.github.io" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw'></i>  </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Shiori&#39;s Blog"><img
        class="lazyload logo"
        src="/svg/loading.min.svg"
        data-src="/icons/favicon-32x32.png"
        data-srcset="/icons/favicon-32x32.png, /icons/favicon-32x32.png 1.5x, /icons/favicon-32x32.png 2x"
        data-sizes="auto"
        alt="/icons/favicon-32x32.png"
        title="/icons/favicon-32x32.png" />Shiori&#39;s Blog</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        取消
                    </a>
                </div><a class="menu-item" href="http://kanshiori.cn" title="" rel="noopener noreffer" target="_blank">主页</a><a class="menu-item" href="/posts/" title="">所有文章</a><a class="menu-item" href="/tags/" title="">标签</a><a class="menu-item" href="/categories/" title="">分类</a><a class="menu-item" href="/about/" title="">关于</a><a class="menu-item" href="https://github.com/KanShiori/KanShiori.github.io" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw'></i></a><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><div class="search-dropdown desktop">
        <div id="search-dropdown-desktop"></div>
    </div>
    <div class="search-dropdown mobile">
        <div id="search-dropdown-mobile"></div>
    </div><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">目录</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">KVM 虚拟机的存储与网络总结</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>Shiori</a></span>&nbsp;<span class="post-category">收录于 <a href="/categories/vm/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>VM</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="2020-11-28">2020-11-28</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;约 6866 字&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;预计阅读 14 分钟&nbsp;</div>
        </div><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>目录</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#1-virtio-概述">1 virtio 概述</a>
      <ul>
        <li><a href="#11-全模拟-io-设备基本原理">1.1 全模拟 I/O 设备基本原理</a></li>
        <li><a href="#12-virtio-基本原理">1.2 virtio 基本原理</a></li>
        <li><a href="#13-vhost">1.3 vhost</a></li>
        <li><a href="#14-总结">1.4 总结</a></li>
      </ul>
    </li>
    <li><a href="#2-设备直接分配">2 设备直接分配</a>
      <ul>
        <li><a href="#21-pci-设备直接分配">2.1 PCI 设备直接分配</a></li>
        <li><a href="#22-sr-iov">2.2 SR-IOV</a></li>
      </ul>
    </li>
    <li><a href="#3-存储模式">3 存储模式</a>
      <ul>
        <li><a href="#31-纯模拟">3.1 纯模拟</a></li>
        <li><a href="#32-virtio-blk">3.2 virtio-blk</a></li>
        <li><a href="#33-virtio-scsi">3.3 virtio-scsi</a></li>
        <li><a href="#34-设备直接分配">3.4 设备直接分配</a>
          <ul>
            <li><a href="#341-pci-设备">3.4.1 PCI 设备</a></li>
            <li><a href="#342-scsi-设备">3.4.2 SCSI 设备</a></li>
          </ul>
        </li>
        <li><a href="#35-libvirt-提供的存储模型">3.5 libvirt 提供的存储模型</a></li>
      </ul>
    </li>
    <li><a href="#4-网络模式">4 网络模式</a>
      <ul>
        <li><a href="#41-虚拟机网络">4.1 虚拟机网络</a>
          <ul>
            <li><a href="#411-nat-mode">4.1.1 NAT Mode</a></li>
            <li><a href="#412-routed-mode">4.1.2 Routed Mode</a></li>
          </ul>
        </li>
        <li><a href="#42-共享物理设备网络">4.2 共享物理设备网络</a>
          <ul>
            <li><a href="#421-bridge">4.2.1 Bridge</a></li>
            <li><a href="#422-macvtap">4.2.2 Macvtap</a></li>
          </ul>
        </li>
        <li><a href="#43-设备直接分配">4.3 设备直接分配</a>
          <ul>
            <li><a href="#431-pci-网卡">4.3.1 PCI 网卡</a></li>
            <li><a href="#431-sr-iov">4.3.1 SR-IOV</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#参考">参考</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><blockquote>
<p><strong>总结系列的文章</strong>是自己的学习或使用后，对相关知识的一个总结，用于后续可以快速复习与回顾。</p>
</blockquote>
<p>本文主要总结一些遇到的虚拟机使用存储与网络的方式，挖了许多坑，不断补充中。</p>
<p>下面所有的虚拟机启动都使用 libvirt，通过修改其配置文件来设置网络或者存储，省略了虚拟机的启动、停止等操作命令。</p>
<h2 id="1-virtio-概述">1 virtio 概述</h2>
<p>KVM 在 IO 虚拟化方面，传统的方式是使用 QEMU 纯软件方式模拟网卡、磁盘。</p>
<p>KVM 中，可以在客户机使用 <strong><ruby>半虚拟化驱动<rt>Paravirtualized Drivers</rt></ruby></strong> 来提高客户机性能。</p>
<p>目前，采用的是 virtio 这个设备驱动标准框架。</p>
<h3 id="11-全模拟-io-设备基本原理">1.1 全模拟 I/O 设备基本原理</h3>
<p>纯软件模拟 I/O 如下图所示：








    <br><img src="/posts/cloud/vm/kvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E5%AD%98%E5%82%A8%E4%B8%8E%E7%BD%91%E7%BB%9C/img1.png"/>


</p>
<ol>
<li>客户机中设备驱动程序（Device Driver）发起 I/O 操作请求时，KVM 内核模块会拦截这次请求，然后将请求信息放到 I/O 共享页（sharing page）；</li>
<li>KVM 模块通知用户空间 QEMU 程序（客户机对应 qemu 进程的一个线程）有 I/O 请求；</li>
<li>QEMU 模拟程序根据 I/O 请求信息，交由硬件模拟代码（Emulation Code）模拟 I/O 请求，阻塞等待 I/O 结果；</li>
<li>如果是普通的 I/O 请求完成后，将结果放回到 I/O 共享页；
如果客户机是通过 DMA 访问大块 I/O 时，QEMU 模拟程序会直接通过内存映射的将结果直接写到客户机内存中，并通知 KVM 模块客户机 DMA 操作已经完成；</li>
<li>KVM 内核模块读取 I/O 共享页中结果，将结果返回给客户机；
或者，接受到 QEMU 通知，通知客户机 DMA 操作已经完成；</li>
</ol>
<p>QEMU 模拟 I/O 设备的优点：可以通过软件模拟出各种设备，兼容性好。但是也有明显缺点：每次 I/O 操作比较长，有较多的 VMEntry、VMExit 发生，需要多次上下文切换与数据复制，性能很差。</p>
<h3 id="12-virtio-基本原理">1.2 virtio 基本原理</h3>
<p><strong><code>virtio</code></strong> 是一个在 Hypervisor 上抽象 API 接口，让客户机知道运行与虚拟化环境中，进而根据 virtio 标准与 Hypervisor 协作，从而在客户机达到更好性能。</p>
<p>其 virtio 基本结构如下：








    <br><img src="/posts/cloud/vm/kvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E5%AD%98%E5%82%A8%E4%B8%8E%E7%BD%91%E7%BB%9C/img2.png"/>


</p>
<ul>
<li><strong><ruby>前端驱动<rt>fronded</rt></ruby></strong> 是在客户机中的驱动模块，如 virtio-blk、virtio-net 等；</li>
<li><strong><ruby>后端处理程序<rt>backend</rt></ruby></strong> 在 QEMU 中实现，执行具体的 I/O 操作；</li>
<li><strong><code>virtio</code></strong> 是虚拟队列接口，在逻辑上将前端驱动附加到后端处理程序，虚拟队列实际上被实现为跨越客户机操作系统和 Hypervisor 的衔接点，该衔接点可以用任意方式实现，前提是前后端都遵循标准实现。
一个前端驱动可以有 0 或多个队列，例如 virtio-net 使用两个虚拟队列（接受+发送）。</li>
<li><strong><code>virtio-ring</code></strong> 实现了环形缓冲区（ring buffer），用于保存前端驱动和后端处理程序执行的信息。
环形缓冲区可以一次性保存前端驱动多个 I/O 请求，并交由后端驱动批量处理，最后实际调用宿主机设备驱动实现的设备 I/O 操作，以提升效率。</li>
</ul>
<p>virtio 的性能很好，一般都推荐使用 virtio。但是，virtio 要求客户机必须安装特定的 virtio 驱动，并且按照 virtio 规定格式传输数据，一些老的 Linux 系统可能不支持。</p>
<p>在客户机中查看是否存在 virtio 相关内核模块，以确定系统是否支持 virtio：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="o">[</span>root@kvm-guest ~<span class="o">]</span><span class="c1"># lsmod | grep virtio</span>
virtio_net             <span class="m">28024</span>  <span class="m">0</span> 
virtio_pci             <span class="m">22913</span>  <span class="m">0</span> 
virtio_ring            <span class="m">21524</span>  <span class="m">2</span> virtio_net,virtio_pci
virtio                 <span class="m">15008</span>  <span class="m">2</span> virtio_net,virtio_pci
</code></pre></td></tr></table>
</div>
</div><p>其中，virtio、virtio_ring、virtio_pci 等驱动提供对 virtio API 支持，任何 virtio 前端驱动都必须使用。</p>
<h3 id="13-vhost">1.3 vhost</h3>
<p>正如 <a href="#12-virtio-%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86" rel=""><strong>前面所述</strong></a>，virtio 分为前后端，而后端默认为用户空间的 QEMU 进程。由 QEMU 进程模拟虚拟机的命令，在将结果返回给虚拟机。可以看到，这里存在着一次 用户空间至内核空间的转换。</p>
<p>而 vhost 出现就是用于优化这一次的转换。<strong><code>vhost</code></strong> 是宿主机中的一个内核模块，用于和虚拟机直接进行通信，也是通过 virtio 提供的数据队列进行通信。</p>
<p>目前，网络支持有 vhost-net，块设备支持有 vhost-blk，它们都依赖于基础的内核模块 vhost。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">$ lsmod <span class="p">|</span> grep  vhost
vhost_net              <span class="m">28672</span>  <span class="m">1</span>
vhost                  <span class="m">53248</span>  <span class="m">1</span> vhost_net
vhost_iotlb            <span class="m">16384</span>  <span class="m">1</span> vhost
</code></pre></td></tr></table>
</div>
</div><h3 id="14-总结">1.4 总结</h3>
<p>首先，需要明白 virtio 为什么比纯模拟的方式快？</p>
<p>最主要因为纯模拟的方式存在多次内核 KVM 与用户空间 QEMU 进程的数据交互，简单点说，客户机需要 KVM 进行数据的中转。</p>
<p>而 <strong>virtio 消除了 KVM 进行数据的中转，通过一套标准框架实现虚拟机与 QEMU 进程的直接信息交互</strong>。也是因此，虚拟机需要使用特殊的 virtio 相关的驱动，也就知道了自己处于虚拟化环境，所以是半虚拟化。</p>
<p>其次，需要明确，virtio 由前后端组成，其中<strong>后端是由 QEMU 实现的</strong>，目前主流的 QEMU 版本都实现了，不需要 care。而需要注意的是，<strong>virtio 的前端是要在虚拟机中满足</strong>，也就是相关的 virtio 驱动，这在使用时需要进行确认。</p>
<p>而 virtio 的通信方式中，还存在 QEMU 模拟命令执行这一个优化点，因此，<strong>vhost 出现优化了这一次的用户空间至内核空间的切换</strong>。</p>
<h2 id="2-设备直接分配">2 设备直接分配</h2>
<h3 id="21-pci-设备直接分配">2.1 PCI 设备直接分配</h3>
<p><strong><code>PCI 设备直接分配</code></strong> 允许将宿主机的物理 PCI（或 PCI-E）设备直接分配给客户机完全使用。</p>
<p>设备直接分配相当于虚拟机直接使用硬件设备，也就没有了 QEMU 进程的模拟，因此速度最快。</p>
<p>但是，设备直接分配有一些条件：</p>
<ul>
<li>硬件平台需要支持 Intel 硬件支持设备直接分配规范为 &ldquo;Intel(R)Virtualization Technology for Directed I/O&rdquo;（VT-d）或者 AMD 的规范为 &ldquo;AMD-Vi&rdquo;（也叫作 IOMMU）。
目前市面上的 x86 硬件平台基本都支持 VT-d，在 BIOS 中设置打开 VT-d 特性。</li>
<li>内核配置支持相关 VT-d 的特性，并且加载内核模块 vfio-pci（内核 &gt;= 3.10）。</li>
<li>内核启动参数需要打开 intel_iommu=on（intel 平台）</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">$ modprobe vfio_pci
$ lsmod <span class="p">|</span> grep vfio
vfio_pci               <span class="m">53248</span>  <span class="m">0</span>
vfio_virqfd            <span class="m">16384</span>  <span class="m">1</span> vfio_pci
vfio_iommu_type1       <span class="m">32768</span>  <span class="m">0</span>
vfio                   <span class="m">36864</span>  <span class="m">2</span> vfio_iommu_type1,vfio_pci
irqbypass              <span class="m">16384</span>  <span class="m">8</span> vfio_pci,kvm
</code></pre></td></tr></table>
</div>
</div><h3 id="22-sr-iov">2.2 SR-IOV</h3>
<p>VT-d 技术只能讲一个物理设备分配给一个客户机使用，为了让多个虚拟机共享同一个物理设备，PCI_SIG 组织发布了
<strong><ruby>SR-IOV<rt>Single Root I/O Virtualizaiton and Sharing</rt></ruby></strong> 规范，该规范定义了标准化机制，用以原生的支持多个共享的设备（不一定网卡）。</p>
<p>目前，SR-IOV 最广泛应用在以太网设备的虚拟化方面。</p>
<p>SR-IOV 引入了两个新的 function：</p>
<ul>
<li><strong><ruby>PF 物理功能<rt>Physical Function</rt></ruby></strong> ：PF 是一个普通的 PCI-e 设备（带有 SR-IOV 功能），在宿主机中配置和管理其他 VF，本身也可以作为独立 function 使用；</li>
<li><strong><ruby>VF 虚拟功能<rt>Virtual Function</rt></ruby></strong> ：由 PF 衍生的 &ldquo;轻量级&rdquo; PCI-e 功能，可以分配到客户机中作为独立 function 使用；</li>
</ul>
<p>SR-IOV 为客户机中使用的 VF 提供了独立的内存空间、中断、DMA 流，从而不需要 Hypervisor 介入数据传输。








    <br><img src="/posts/cloud/vm/kvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E5%AD%98%E5%82%A8%E4%B8%8E%E7%BD%91%E7%BB%9C/img3.png"/>


</p>
<p>一个具有 SR-IOV 功能的设备能够被配置为 PCI 配置空间中呈现出多个 Function（1 个 PF + 多个 VF），每个 VF 有独立的配置空间和完整的 BAR（Base Address Register，基址寄存器）。</p>
<p>Hypervisor 通过将 VF 实际的配置空间映射到客户机看到的配置空间的方式，将一个或多个 VF 分配给一个客户机。并且，通过 Intel VT-x 和 VT-d 等硬件辅助虚拟化技术提供的内存转换技术，允许直接的 DMA 传输去往或来自一个客户机，因此几乎不需要 Hypervisor 的参与。</p>
<p>在客户机中看到的 VF，表现给客户机操作系统的就是一个完整的普通的设备。








    <br><img src="/posts/cloud/vm/kvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E5%AD%98%E5%82%A8%E4%B8%8E%E7%BD%91%E7%BB%9C/img4.png"/>


</p>
<p>SR-IOV 需要硬件平台支持 Intel VT-x 和 VT-d（或 AMD 的 SVM 和 IOMMU）虚拟化特性，并且需要具体设备支持 SR-IOV 规范。</p>
<p>在 Linux 中，可以查看 PCI 信息的“Capabilities”项目，以确定设备是否具备 SR-IOV 功能：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">$ lspci -s 82:00.0 -v
82:00.0 Ethernet controller: Intel Corporation I350 Gigabit Network Connection <span class="o">(</span>rev 01<span class="o">)</span>
        Flags: bus master, fast devsel, latency 0, IRQ 38, NUMA node <span class="m">1</span>
        Memory at d0100000 <span class="o">(</span>32-bit, non-prefetchable<span class="o">)</span> <span class="o">[</span><span class="nv">size</span><span class="o">=</span>1M<span class="o">]</span>
        I/O ports at c020 <span class="o">[</span><span class="nv">size</span><span class="o">=</span>32<span class="o">]</span>
        Memory at d0204000 <span class="o">(</span>32-bit, non-prefetchable<span class="o">)</span> <span class="o">[</span><span class="nv">size</span><span class="o">=</span>16K<span class="o">]</span>
        Expansion ROM at d0400000 <span class="o">[</span>disabled<span class="o">]</span> <span class="o">[</span><span class="nv">size</span><span class="o">=</span>1M<span class="o">]</span>
        Capabilities: <span class="o">[</span>40<span class="o">]</span> Power Management version <span class="m">3</span>
        Capabilities: <span class="o">[</span>50<span class="o">]</span> MSI: Enable- <span class="nv">Count</span><span class="o">=</span>1/1 Maskable+ 64bit+
        Capabilities: <span class="o">[</span>70<span class="o">]</span> MSI-X: Enable+ <span class="nv">Count</span><span class="o">=</span><span class="m">10</span> Masked-
        Capabilities: <span class="o">[</span>a0<span class="o">]</span> Express Endpoint, MSI <span class="m">00</span>
        Capabilities: <span class="o">[</span>100<span class="o">]</span> Advanced Error Reporting
        Capabilities: <span class="o">[</span>140<span class="o">]</span> Device Serial Number a4-dc-be-ff-ff-17-8d-52
        Capabilities: <span class="o">[</span>150<span class="o">]</span> Alternative Routing-ID Interpretation <span class="o">(</span>ARI<span class="o">)</span>
        Capabilities: <span class="o">[</span>160<span class="o">]</span> Single Root I/O Virtualization <span class="o">(</span>SR-IOV<span class="o">)</span>
        Capabilities: <span class="o">[</span>1a0<span class="o">]</span> Transaction Processing Hints
        Capabilities: <span class="o">[</span>1c0<span class="o">]</span> Latency Tolerance Reporting
        Capabilities: <span class="o">[</span>1d0<span class="o">]</span> Access Control Services
        Kernel driver in use: igb
        Kernel modules: igb
</code></pre></td></tr></table>
</div>
</div><ul>
<li><em>&ldquo;Capabilities: [160] Single Root I/O Virtualization (SR-IOV)&quot;</em> 表示网卡支持 SR-IOV 功能
具体使用方式见网络模式中的示例。</li>
</ul>
<h2 id="3-存储模式">3 存储模式</h2>
<p>下面的磁盘测试都是以 4k 随机读写测试，命令如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">fio -thread -name<span class="o">=</span><span class="si">${</span><span class="nv">DISK</span><span class="si">}</span> -filename<span class="o">=</span><span class="si">${</span><span class="nv">DISK</span><span class="si">}</span> <span class="se">\
</span><span class="se"></span>        -ioengine<span class="o">=</span>libaio -direct<span class="o">=</span><span class="m">1</span> -bs<span class="o">=</span>4k -rw<span class="o">=</span>randrw -iodepth<span class="o">=</span><span class="m">32</span> <span class="se">\
</span><span class="se"></span>        -size<span class="o">=</span>8G  -rw<span class="o">=</span>readrw
</code></pre></td></tr></table>
</div>
</div><p>说明，测试仅仅适用于简单对比各个模式之间性能差异，而不是标准的基准测试，不能作为靠谱数据。</p>
<h3 id="31-纯模拟">3.1 纯模拟</h3>
<p>纯模拟是最简单的方式，所有的 IO 请求发送给 QEMU，由 QEMU 在宿主机执行后将结果返回给虚拟机中（见 1.1）。</p>
<p>创建一个 qcow2 文件，并将其以 sata 驱动方式提供给虚拟机：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">…
&lt;disk <span class="nv">type</span><span class="o">=</span><span class="s1">&#39;file&#39;</span> <span class="nv">device</span><span class="o">=</span><span class="s1">&#39;disk&#39;</span>&gt;
      &lt;driver <span class="nv">name</span><span class="o">=</span><span class="s1">&#39;qemu&#39;</span> <span class="nv">type</span><span class="o">=</span><span class="s1">&#39;qcow2&#39;</span>/&gt;
      &lt;<span class="nb">source</span> <span class="nv">file</span><span class="o">=</span><span class="s1">&#39;/root/disk1.qcow2&#39;</span>/&gt;
      &lt;target <span class="nv">dev</span><span class="o">=</span><span class="s1">&#39;sda&#39;</span> <span class="nv">bus</span><span class="o">=</span><span class="s1">&#39;sata&#39;</span>/&gt;
      &lt;address <span class="nv">type</span><span class="o">=</span><span class="s1">&#39;drive&#39;</span> <span class="nv">controller</span><span class="o">=</span><span class="s1">&#39;0&#39;</span> <span class="nv">bus</span><span class="o">=</span><span class="s1">&#39;0&#39;</span> <span class="nv">target</span><span class="o">=</span><span class="s1">&#39;0&#39;</span> <span class="nv">unit</span><span class="o">=</span><span class="s1">&#39;0&#39;</span>/&gt;
&lt;/disk&gt;
…
</code></pre></td></tr></table>
</div>
</div><p>在虚拟机中，可以看到对应的磁盘与对应的驱动：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="o">[</span>root@localhost ~<span class="o">]</span><span class="c1"># lsblk</span>
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sda      8:0    <span class="m">0</span>  500G  <span class="m">0</span> disk
vda    253:0    <span class="m">0</span>  500G  <span class="m">0</span> disk
└─vda1 253:1    <span class="m">0</span>  500G  <span class="m">0</span> part /
<span class="o">[</span>root@localhost ~<span class="o">]</span><span class="c1"># lspci</span>
…
00:09.0 SATA controller: Intel Corporation 82801IR/IO/IH <span class="o">(</span>ICH9R/DO/DH<span class="o">)</span> <span class="m">6</span> port SATA Controller <span class="o">[</span>AHCI mode<span class="o">]</span> <span class="o">(</span>rev 02<span class="o">)</span>
</code></pre></td></tr></table>
</div>
</div><p>压测结果：</p>
<ul>
<li>read: IOPS=9183, BW=35.9MiB/s (37.6MB/s)(4098MiB/114246msec)</li>
<li>write: IOPS=9172, BW=35.8MiB/s (37.6MB/s)(4094MiB/114246msec)</li>
</ul>
<h3 id="32-virtio-blk">3.2 virtio-blk</h3>
<p><strong><code>virtio-blk</code></strong> 实现了 virtio 标准，在虚拟机中使用 virtio 驱动，加速存储的访问。当然，需要客户机中系统支持 virtio-blk 内核模块。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="o">[</span>root@localhost ~<span class="o">]</span><span class="c1"># lsmod | grep blk</span>
virtio_blk             <span class="m">18323</span>  <span class="m">2</span>
</code></pre></td></tr></table>
</div>
</div><p>目前，virtio-blk 可用于宿主机文件、裸设备、LVM 设备，挂载到虚拟机后命名为 vdx。</p>
<p>将 &lt;disk&gt;.&lt;target&gt; 中的 bus 改为 virtio，就是使用 virtio-blk 方式。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">…
&lt;disk <span class="nv">type</span><span class="o">=</span><span class="s1">&#39;file&#39;</span> <span class="nv">device</span><span class="o">=</span><span class="s1">&#39;disk&#39;</span>&gt;
      &lt;driver <span class="nv">name</span><span class="o">=</span><span class="s1">&#39;qemu&#39;</span> <span class="nv">type</span><span class="o">=</span><span class="s1">&#39;qcow2&#39;</span>/&gt;
      &lt;<span class="nb">source</span> <span class="nv">file</span><span class="o">=</span><span class="s1">&#39;/root/disk1.qcow2&#39;</span>/&gt;
      &lt;target <span class="nv">dev</span><span class="o">=</span><span class="s1">&#39;sda&#39;</span> <span class="nv">bus</span><span class="o">=</span><span class="s1">&#39;virtio&#39;</span>/&gt;
      &lt;address <span class="nv">type</span><span class="o">=</span><span class="s1">&#39;pci&#39;</span> <span class="nv">domain</span><span class="o">=</span><span class="s1">&#39;0x0000&#39;</span> <span class="nv">bus</span><span class="o">=</span><span class="s1">&#39;0x00&#39;</span> <span class="nv">slot</span><span class="o">=</span><span class="s1">&#39;0x0a&#39;</span> <span class="k">function</span><span class="o">=</span><span class="s1">&#39;0x0&#39;</span>/&gt;
&lt;/disk&gt;
…
</code></pre></td></tr></table>
</div>
</div><p>不过使用 virtio 驱动，设置的 dev 名称会失效，自动使用 vdx 这种命名方式。在虚拟机中看到对应的磁盘以及驱动：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="o">[</span>root@localhost ~<span class="o">]</span><span class="c1"># lsblk</span>
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
vda    253:0    <span class="m">0</span>  500G  <span class="m">0</span> disk
└─vda1 253:1    <span class="m">0</span>  500G  <span class="m">0</span> part /
vdb    253:16   <span class="m">0</span>  500G  <span class="m">0</span> disk
<span class="o">[</span>root@localhost ~<span class="o">]</span><span class="c1"># lspci</span>
…
00:0a.0 SCSI storage controller: Red Hat, Inc. Virtio block device
</code></pre></td></tr></table>
</div>
</div><p>压测结果，可以看到，比纯模拟要快很多：</p>
<ul>
<li>read: IOPS=41.7k, BW=163MiB/s (171MB/s)(4098MiB/25145msec)</li>
<li>write: IOPS=41.7k, BW=163MiB/s (171MB/s)(4094MiB/25145msec)</li>
</ul>
<p>virtio-blk 虽然提供了很高的存储访问性能，但是其设计上也有着一些缺点：</p>
<ul>
<li>virtio blk 的范围有限，这使得新的命令实现变得复杂。每次开发一个新命令时，virtio blk 驱动程序都必须在每个客户机中更新</li>
<li><strong>virtio blk 将 PCI 功能和存储设备映射为 1:1，一个映射就需要占用虚拟机一个 PCI 地址</strong>，限制了可扩展性。</li>
<li>virtio blk 不是真正的 SCSI 设备。这会导致一些应用程序在从物理机移动到虚拟机时中断。</li>
</ul>
<h3 id="33-virtio-scsi">3.3 virtio-scsi</h3>
<p><strong><code>virito-scsi</code></strong> 有着与 virtio-blk 相同的性能，但是改善了 virtio-blk 的相关缺点，其中最大的优势就是 virtio-scsi 可以允许虚拟机处理数百个设备，而 virtio-blk 只能处理大约 30 个设备就会耗尽 PCI 插槽。</p>
<p>因为 virtio-scsi 在虚拟机里使用的是 scsi 驱动，因此设备的命名也变为了 sdx。</p>
<p>将磁盘的驱动设置为 scsi，同时将 scsi 驱动设置为使用 <strong>virtio-scsi</strong>（默认使用的驱动是 lsi）：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">…
    &lt;disk <span class="nv">type</span><span class="o">=</span><span class="s1">&#39;file&#39;</span> <span class="nv">device</span><span class="o">=</span><span class="s1">&#39;disk&#39;</span>&gt;
      &lt;driver <span class="nv">name</span><span class="o">=</span><span class="s1">&#39;qemu&#39;</span> <span class="nv">type</span><span class="o">=</span><span class="s1">&#39;qcow2&#39;</span>/&gt;
      &lt;<span class="nb">source</span> <span class="nv">file</span><span class="o">=</span><span class="s1">&#39;/root/disk1.qcow2&#39;</span>/&gt;
      &lt;target <span class="nv">dev</span><span class="o">=</span><span class="s1">&#39;sdc&#39;</span> <span class="nv">bus</span><span class="o">=</span><span class="s1">&#39;scsi&#39;</span>/&gt;
      &lt;address <span class="nv">type</span><span class="o">=</span><span class="s1">&#39;drive&#39;</span> <span class="nv">controller</span><span class="o">=</span><span class="s1">&#39;0&#39;</span> <span class="nv">bus</span><span class="o">=</span><span class="s1">&#39;0&#39;</span> <span class="nv">target</span><span class="o">=</span><span class="s1">&#39;0&#39;</span> <span class="nv">unit</span><span class="o">=</span><span class="s1">&#39;2&#39;</span>/&gt;
    &lt;/disk&gt;
    &lt;controller <span class="nv">type</span><span class="o">=</span><span class="s1">&#39;scsi&#39;</span> <span class="nv">index</span><span class="o">=</span><span class="s1">&#39;0&#39;</span> <span class="nv">model</span><span class="o">=</span><span class="s1">&#39;virtio-scsi&#39;</span>/&gt;
…
</code></pre></td></tr></table>
</div>
</div><ul>
<li>可以看到，&lt;address&gt; 中设置相关设备地址时，可以看到不是设置 pci 槽地址，而是设置设备对应 SCSI 映射地址，因此通过增加 &ldquo;target&rdquo; 属性就可以添加多个硬盘，不需要占用多个 PCI 槽；</li>
</ul>
<p>虚拟机中看到对应的块设备 &ldquo;sda&rdquo;，以及驱动 &ldquo;Virtio SCSI&rdquo;：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="o">[</span>root@localhost ~<span class="o">]</span><span class="c1"># lsblk</span>
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sda      8:0    <span class="m">0</span>  500G  <span class="m">0</span> disk
vda    253:0    <span class="m">0</span>  500G  <span class="m">0</span> disk
└─vda1 253:1    <span class="m">0</span>  500G  <span class="m">0</span> part /
<span class="o">[</span>root@localhost ~<span class="o">]</span><span class="c1"># lspci</span>
…
00:08.0 SCSI storage controller: Red Hat, Inc. Virtio SCSI
</code></pre></td></tr></table>
</div>
</div><p>压测结果：</p>
<ul>
<li>read: IOPS=45.5k, BW=178MiB/s (186MB/s)(4098MiB/23055msec)</li>
<li>write: IOPS=46.2k, BW=180MiB/s (189MB/s)(4094MiB/22695msec)</li>
</ul>
<p>目前，virtio-scsi 还存在一种设备直通的模式，IO 性能更高（具体实现原理还不了解）。但是，这种模式还能用于块设备，并且是使用 scsi 协议的块设备（测试文件、usb 都不支持）。</p>
<p>通过设置 <strong>device=&ldquo;lun&rdquo;</strong> 使用：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">...
    &lt;disk <span class="nv">type</span><span class="o">=</span><span class="s1">&#39;block&#39;</span> <span class="nv">device</span><span class="o">=</span><span class="s1">&#39;lun&#39;</span>&gt;
      &lt;driver <span class="nv">name</span><span class="o">=</span><span class="s1">&#39;qemu&#39;</span> <span class="nv">type</span><span class="o">=</span><span class="s1">&#39;raw&#39;</span>/&gt;
      &lt;<span class="nb">source</span> <span class="nv">dev</span><span class="o">=</span><span class="s1">&#39;/dev/sda&#39;</span>/&gt;
      &lt;target <span class="nv">dev</span><span class="o">=</span><span class="s1">&#39;sdc&#39;</span> <span class="nv">bus</span><span class="o">=</span><span class="s1">&#39;scsi&#39;</span>/&gt;
      &lt;address <span class="nv">type</span><span class="o">=</span><span class="s1">&#39;drive&#39;</span> <span class="nv">controller</span><span class="o">=</span><span class="s1">&#39;0&#39;</span> <span class="nv">bus</span><span class="o">=</span><span class="s1">&#39;0&#39;</span> <span class="nv">target</span><span class="o">=</span><span class="s1">&#39;0&#39;</span> <span class="nv">unit</span><span class="o">=</span><span class="s1">&#39;2&#39;</span>/&gt;
    &lt;/disk&gt;
    &lt;controller <span class="nv">type</span><span class="o">=</span><span class="s1">&#39;scsi&#39;</span> <span class="nv">index</span><span class="o">=</span><span class="s1">&#39;0&#39;</span> <span class="nv">model</span><span class="o">=</span><span class="s1">&#39;virtio-scsi&#39;</span> /&gt;
...
</code></pre></td></tr></table>
</div>
</div><ul>
<li>使用 lun 方式，并指定使用宿主机块设备 sda</li>
</ul>
<p>虚拟机中看到对应块设备 &ldquo;sda&rdquo;，以及驱动 &quot;&rdquo; ：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="o">[</span>root@localhost ~<span class="o">]</span><span class="c1"># lsblk</span>
NAME   MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT
sda      8:0    <span class="m">0</span> 465.8G  <span class="m">0</span> disk
vda    253:0    <span class="m">0</span>   500G  <span class="m">0</span> disk
└─vda1 253:1    <span class="m">0</span>   500G  <span class="m">0</span> part /
<span class="o">[</span>root@localhost ~<span class="o">]</span><span class="c1"># lspci</span>
…
00:08.0 SCSI storage controller: Red Hat, Inc. Virtio SCSI
</code></pre></td></tr></table>
</div>
</div><div class="details admonition warning open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-exclamation-triangle fa-fw" aria-hidden="true"></i>发现的问题<i class="details-icon fas fa-angle-right fa-fw" aria-hidden="true"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content"><p>在使用 lun 分配磁盘时，发现虚拟机内部对磁盘的修改，在宿主机上是无法可见的（可能出现磁盘文件系统 UUID 都不一致的问题）。并且，在虚拟机内部给磁盘创建文件系统还会出现有报错的情况。</p>
<p>如果是要将 scsi 磁盘单独分给虚拟机，推荐使用设备直接分配中的 <a href="#342-scsi-%e8%ae%be%e5%a4%87" rel=""><strong>scsi 设备分配</strong></a>。</p>
</div>
        </div>
    </div>
<h3 id="34-设备直接分配">3.4 设备直接分配</h3>
<h4 id="341-pci-设备">3.4.1 PCI 设备</h4>
<p>在 <a href="#21-pci-%e8%ae%be%e5%a4%87%e7%9b%b4%e6%8e%a5%e5%88%86%e9%85%8d" rel=""><strong>2.1 PCI 设备直接分配</strong></a> 中所说，PCI 设备都支持进行设备直接分配，使得虚拟机中直接对 PCI 设备进行访问，速度最快。nvme 磁盘可以使用这种方式。</p>
<p>使用设备直接分配时，需要现在宿主机上取消对应设备的驱动绑定，然后将其分配给虚拟机，然后 libvirt 中配置好相关参数后，会自动帮我们执行这些步骤。</p>
<p>在设备 xml 配置文件中添加 <strong>&lt;hostdev&gt;</strong> 项，指定对应的设备 PCI 地址，来直接分配设备（也可以使用 <strong>&lt;interface type=&lsquo;hostdev&rsquo;/&gt;</strong>，这是一种 libvirt 提供的较新的配置方式，但是不兼容所有设备）。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">…
    &lt;hostdev <span class="nv">mode</span><span class="o">=</span><span class="s1">&#39;subsystem&#39;</span> <span class="nv">type</span><span class="o">=</span><span class="s1">&#39;pci&#39;</span> <span class="nv">managed</span><span class="o">=</span><span class="s1">&#39;yes&#39;</span>&gt;
        &lt;source&gt;
            &lt;address <span class="nv">domain</span><span class="o">=</span><span class="s1">&#39;0x0000&#39;</span> <span class="nv">bus</span><span class="o">=</span><span class="s1">&#39;0x08&#39;</span> <span class="nv">slot</span><span class="o">=</span><span class="s1">&#39;0x00&#39;</span> <span class="k">function</span><span class="o">=</span><span class="s1">&#39;0x0&#39;</span>/&gt;
        &lt;/source&gt;
    &lt;/hostdev&gt;
…
</code></pre></td></tr></table>
</div>
</div><h4 id="342-scsi-设备">3.4.2 SCSI 设备</h4>
<p>对于 SCSI 磁盘，通过 PCI 无法单独分配某个磁盘，而 libvirt 中提供了 <strong>type=&lsquo;scsi&rsquo;</strong> 类型的直接分配。但是与 PCI 不同的是，scsi 无法设置 &lsquo;managed&rsquo; 参数，也就是说宿主机上还是能够看见该 scsi 设备，如果想不可见，需要自己 unbind。</p>
<p>添加 scsi 类型的 <strong>&lt;hostdev&gt;</strong> 项，其中 &lt;source&gt;.&lt;address&gt; 中指定宿主机对应磁盘的 scsi 地址。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">...
    &lt;hostdev <span class="nv">mode</span><span class="o">=</span><span class="s1">&#39;subsystem&#39;</span> <span class="nv">type</span><span class="o">=</span><span class="s1">&#39;scsi&#39;</span> <span class="nv">managed</span><span class="o">=</span><span class="s1">&#39;no&#39;</span> <span class="nv">sgio</span><span class="o">=</span><span class="s1">&#39;filtered&#39;</span> <span class="nv">rawio</span><span class="o">=</span><span class="s1">&#39;yes&#39;</span>&gt;
        &lt;source&gt;
            &lt;adapter <span class="nv">name</span><span class="o">=</span><span class="s1">&#39;scsi_host0&#39;</span>/&gt;
            &lt;address <span class="nv">bus</span><span class="o">=</span><span class="s1">&#39;2&#39;</span> <span class="nv">target</span><span class="o">=</span><span class="s1">&#39;1&#39;</span> <span class="nv">unit</span><span class="o">=</span><span class="s1">&#39;0&#39;</span>/&gt;
        &lt;/source&gt;
            &lt;address <span class="nv">type</span><span class="o">=</span><span class="s1">&#39;drive&#39;</span> <span class="nv">controller</span><span class="o">=</span><span class="s1">&#39;0&#39;</span> <span class="nv">bus</span><span class="o">=</span><span class="s1">&#39;0&#39;</span> <span class="nv">target</span><span class="o">=</span><span class="s1">&#39;0&#39;</span> <span class="nv">unit</span><span class="o">=</span><span class="s1">&#39;2&#39;</span>/&gt;
    &lt;/hostdev&gt;
    &lt;controller <span class="nv">type</span><span class="o">=</span><span class="s1">&#39;scsi&#39;</span> <span class="nv">index</span><span class="o">=</span><span class="s1">&#39;0&#39;</span> <span class="nv">model</span><span class="o">=</span><span class="s1">&#39;virtio-scsi&#39;</span>/&gt;
...
</code></pre></td></tr></table>
</div>
</div><div class="details admonition note open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fas fa-angle-right fa-fw" aria-hidden="true"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content">这种模式还是会使用 virtio-scsi 驱动，我不确定这是否属于设备直接分配，但是在文档中其属于 passthrough 的一类</div>
        </div>
    </div>
<h3 id="35-libvirt-提供的存储模型">3.5 libvirt 提供的存储模型</h3>
<p>TODO</p>
<h2 id="4-网络模式">4 网络模式</h2>
<p>虚拟机网络的构建一般都是需要构建 宿主机网络环境 + 虚拟机虚拟网络设备，得益于 libvirt，一些常用的网络的构建只需要配置好相关配置就行，libvirt 会进行网络的构建。在 libvirt 中，一个可用的网络就称为 <strong><code>netowrk</code></strong></p>
<p>首先需要明确的，<strong>下面所说的网络模式不同的在于如何让宿主机接收的数据包，到达 <code>qemu 进程</code> 或者 <code>vhost 内核模块</code></strong>。而 qemu 进程与 vhost 模块如何将数据包传递到虚拟机中，这是虚拟化方式的问题，即全虚拟化或者半虚拟化。</p>
<p>更简单点说，虚拟机的网络收发有三个点：<strong>宿主机 &lt;-&gt; qemu/vhost &lt;-&gt; 虚拟机</strong>。而不同网络模式不同点在 宿主机至 qemu/vhost 阶段，而数据包到虚拟机，这就是不同虚拟化的工作了。</p>
<p>在下面的配置中，你会发现网络模式还需要配置 driver 选项，这就是配置具体的虚拟化方式了。但是这不是这里的重点，所以不会有特殊的说明。</p>
<p>libvirt 支持的网络模式有很多，下面仅仅提到我使用过的。</p>
<h3 id="41-虚拟机网络">4.1 虚拟机网络</h3>
<h4 id="411-nat-mode">4.1.1 NAT Mode</h4>
<p>NAT 网络是最简单的网络，不需要任何的依赖。通过虚拟的 bridge 网卡创建一个属于虚拟机的内网，然后在宿主机上通过 iptables 实现内网地址的 NAT。（没错，这和 docker bridge network 的原理一样）








    <br><img src="/posts/cloud/vm/kvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E5%AD%98%E5%82%A8%E4%B8%8E%E7%BD%91%E7%BB%9C/img5.png"/>


</p>
<p>libvirt 会存在一个名为 <strong>default</strong> 的 network，其就是一个 NAT 网络。通过 <code>virsh net-list</code> 查看：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">$ virsh net-list
 Name      State    Autostart   Persistent
--------------------------------------------
 default   active   yes         yes
</code></pre></td></tr></table>
</div>
</div><p>其默认会被 active，也就是说宿主机环境在 libvirtd 启动后就会构建好，你可以看到对应的 bridge 网卡。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">$ ip a
...
3: virbr0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu <span class="m">1500</span> qdisc noqueue state DOWN group default qlen <span class="m">1000</span>
    link/ether 52:54:00:12:34:56 brd ff:ff:ff:ff:ff:ff
    inet 172.27.0.1/16 brd 172.27.255.255 scope global galaxybr0
       valid_lft forever preferred_lft forever
...
</code></pre></td></tr></table>
</div>
</div><p>默认下，default 网络的内网为 192.168.122.1/24，我通过修改其配置文件 <code>/etc/libvirt/qemu/networks/default.xml</code> 修改了内网范围：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">$ cat  /etc/libvirt/qemu/networks/default.xml
&lt;network&gt;
  &lt;name&gt;default&lt;/name&gt;
  &lt;uuid&gt;341adece-b07a-4eb0-92f2-d92f59ed266f&lt;/uuid&gt;
  &lt;forward <span class="nv">mode</span><span class="o">=</span><span class="s1">&#39;nat&#39;</span>/&gt;
  &lt;bridge <span class="nv">name</span><span class="o">=</span><span class="s1">&#39;virbr0&#39;</span> <span class="nv">stp</span><span class="o">=</span><span class="s1">&#39;on&#39;</span> <span class="nv">delay</span><span class="o">=</span><span class="s1">&#39;0&#39;</span>/&gt;
  &lt;mac <span class="nv">address</span><span class="o">=</span><span class="s1">&#39;52:54:00:12:34:56&#39;</span>/&gt;
  &lt;ip <span class="nv">address</span><span class="o">=</span><span class="s1">&#39;172.27.0.1&#39;</span> <span class="nv">netmask</span><span class="o">=</span><span class="s1">&#39;255.255.0.0&#39;</span>&gt;
    &lt;dhcp&gt;
      &lt;range <span class="nv">start</span><span class="o">=</span><span class="s1">&#39;172.27.0.2&#39;</span> <span class="nv">end</span><span class="o">=</span><span class="s1">&#39;172.27.255.254&#39;</span>/&gt;
    &lt;/dhcp&gt;
  &lt;/ip&gt;
&lt;/network&gt;
</code></pre></td></tr></table>
</div>
</div><p>libvirtd 会为启动的 nat 网络启动一个 <strong>dnsmasq</strong> 进程，用于提供 DNS 与 DHCP 功能，其对应配置就是对应网络的配置</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">$ ps x <span class="p">|</span> grep dns
<span class="m">2185</span> ?        S      0:00 /usr/sbin/dnsmasq --conf-file<span class="o">=</span>/var/lib/libvirt/dnsmasq/default.conf --leasefile-ro --dhcp-script<span class="o">=</span>/usr/libexec/libvirt_leaseshelper

$ cat /var/lib/libvirt/dnsmasq/default.conf
strict-order
pid-file<span class="o">=</span>/var/run/libvirt/network/default.pid
except-interface<span class="o">=</span>lo
bind-dynamic
<span class="nv">interface</span><span class="o">=</span>virbr0
dhcp-range<span class="o">=</span>172.27.0.2,172.27.255.254,255.255.0.0
dhcp-no-override
dhcp-authoritative
dhcp-lease-max<span class="o">=</span><span class="m">65533</span>
dhcp-hostsfile<span class="o">=</span>/var/lib/libvirt/dnsmasq/default.hostsfile
addn-hosts<span class="o">=</span>/var/lib/libvirt/dnsmasq/default.addnhosts
</code></pre></td></tr></table>
</div>
</div><p><div class="details admonition note open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fas fa-angle-right fa-fw" aria-hidden="true"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content"><p>这里与 docker bridge network 不同点，因为 docker 中仅仅是 namespace 隔离，容器内网卡 IP 还是可以由 docker 进入 namespace 分配，所以是 docker 承担了 dhcp 服务器的职责。</p>
<p>但是虚拟机和宿主机是强隔离的，因此需要虚拟机启动后去作为 dhcpclient 申请地址，因此需要一个 dhcp 服务，这就是 dnsmasq 的作用。</p>
</div>
        </div>
    </div>
在 xml 配置文件中设置 <strong>&lt;interface type=&lsquo;network&rsquo;&gt;</strong> 项，并设置 <strong>&lt;source network=&lsquo;default&rsquo;/&gt;</strong> 使用 default network。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">&lt;inferface <span class="nv">type</span><span class="o">=</span><span class="s1">&#39;network&#39;</span>&gt;
      &lt;mac <span class="nv">address</span><span class="o">=</span><span class="s1">&#39;50:54:00:87:bc:c3&#39;</span>/&gt;
      &lt;<span class="nb">source</span> <span class="nv">network</span><span class="o">=</span><span class="s1">&#39;default&#39;</span>/&gt;
      &lt;model <span class="nv">type</span><span class="o">=</span><span class="s1">&#39;virtio&#39;</span>/&gt;
      &lt;driver <span class="nv">name</span><span class="o">=</span><span class="s1">&#39;vhost&#39;</span> <span class="nv">txmode</span><span class="o">=</span><span class="s1">&#39;iothread&#39;</span> <span class="nv">ioeventfd</span><span class="o">=</span><span class="s1">&#39;on&#39;</span> <span class="nv">event_idx</span><span class="o">=</span><span class="s1">&#39;off&#39;</span> <span class="nv">queues</span><span class="o">=</span><span class="s1">&#39;16&#39;</span>&gt;
        &lt;host <span class="nv">csum</span><span class="o">=</span><span class="s1">&#39;off&#39;</span> <span class="nv">gso</span><span class="o">=</span><span class="s1">&#39;off&#39;</span> <span class="nv">tso4</span><span class="o">=</span><span class="s1">&#39;off&#39;</span> <span class="nv">tso6</span><span class="o">=</span><span class="s1">&#39;off&#39;</span> <span class="nv">ecn</span><span class="o">=</span><span class="s1">&#39;off&#39;</span> <span class="nv">ufo</span><span class="o">=</span><span class="s1">&#39;off&#39;</span> <span class="nv">mrg_rxbuf</span><span class="o">=</span><span class="s1">&#39;off&#39;</span>/&gt;
        &lt;guest <span class="nv">csum</span><span class="o">=</span><span class="s1">&#39;off&#39;</span> <span class="nv">tso4</span><span class="o">=</span><span class="s1">&#39;off&#39;</span> <span class="nv">tso6</span><span class="o">=</span><span class="s1">&#39;off&#39;</span> <span class="nv">ecn</span><span class="o">=</span><span class="s1">&#39;off&#39;</span> <span class="nv">ufo</span><span class="o">=</span><span class="s1">&#39;off&#39;</span>/&gt;
      &lt;/driver&gt;
    &lt;/interface&gt;
</code></pre></td></tr></table>
</div>
</div><p>启动虚拟机后，可以看到虚拟机内部存在对应的网卡，通过 <code>dhclient -v eth0</code> 命令申请一个 IP，广播的 dhcp request 会被宿主机 dnsmasp 进程响应，并返回 dhcp offer。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="o">[</span>root@localhost ~<span class="o">]</span><span class="c1"># ip a</span>
...
2: eth0: &lt;BROADCAST,MULTICAST&gt; mtu <span class="m">1500</span> qdisc noop state DOWN group default qlen <span class="m">1000</span>
    link/ether 50:54:00:87:bc:c3 brd ff:ff:ff:ff:ff:ff

<span class="o">[</span>root@localhost ~<span class="o">]</span><span class="c1"># dhclient -v  eth0</span>
...
Listening on LPF/eth0/50:54:00:87:bc:c3
Sending on   LPF/eth0/50:54:00:87:bc:c3
Sending on   Socket/fallback
DHCPDISCOVER on eth0 to 255.255.255.255 port <span class="m">67</span> interval <span class="m">4</span> <span class="o">(</span><span class="nv">xid</span><span class="o">=</span>0x57740476<span class="o">)</span>
DHCPREQUEST on eth0 to 255.255.255.255 port <span class="m">67</span> <span class="o">(</span><span class="nv">xid</span><span class="o">=</span>0x57740476<span class="o">)</span>
DHCPOFFER from 172.27.0.1
DHCPACK from 172.27.0.1 <span class="o">(</span><span class="nv">xid</span><span class="o">=</span>0x57740476<span class="o">)</span>
bound to 172.27.163.138 -- renewal in <span class="m">1653</span> seconds.

<span class="o">[</span>root@localhost ~<span class="o">]</span><span class="c1"># ping www.baidu.com</span>
PING www.a.shifen.com <span class="o">(</span>14.215.177.38<span class="o">)</span> 56<span class="o">(</span>84<span class="o">)</span> bytes of data.
<span class="m">64</span> bytes from 14.215.177.38 <span class="o">(</span>14.215.177.38<span class="o">)</span>: <span class="nv">icmp_seq</span><span class="o">=</span><span class="m">1</span> <span class="nv">ttl</span><span class="o">=</span><span class="m">48</span> <span class="nv">time</span><span class="o">=</span>7.93 ms
...
</code></pre></td></tr></table>
</div>
</div><h4 id="412-routed-mode">4.1.2 Routed Mode</h4>
<p>TODO</p>
<h3 id="42-共享物理设备网络">4.2 共享物理设备网络</h3>
<h4 id="421-bridge">4.2.1 Bridge</h4>
<p>TODO</p>
<h4 id="422-macvtap">4.2.2 Macvtap</h4>
<p>在 docker 的网络中，存在着 macvlan 网络，其在宿主机的物理网卡上创建 macvlan 设备，使得在二层上构建多个接口，从而让多个容器处于与宿主机同一个局域网内。在虚拟机网络中，单单 macvlan 网卡无法连接虚拟机设备与宿主机网卡，还需要一个 tap 设备连接，将 macvlan + tap 组合就是 <strong><code>macvtap 设备</code></strong>。</p>
<p>与 macvlan 设备相同，macvtap 同样存在：private、vepa、bridge、passthru 四种模式，下面的示例中都以 bridge 模式为例。</p>
<p>在 libvirt 中，当 interface type 为 <strong>direct</strong> 时，表明设备是直接附加到物理网卡上，而就会使用 macvtap 构建网络。通过 <strong>&lt;source dev=xx mode=xx&gt;</strong> 指定附加的物理网卡，以及 macvtap 的模式。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">...
    &lt;interface <span class="nv">type</span><span class="o">=</span><span class="s1">&#39;direct&#39;</span>&gt;
      &lt;mac <span class="nv">address</span><span class="o">=</span><span class="s1">&#39;50:54:00:87:bc:c3&#39;</span>/&gt;
      &lt;<span class="nb">source</span> <span class="nv">dev</span><span class="o">=</span><span class="s1">&#39;eth3&#39;</span> <span class="nv">mode</span><span class="o">=</span><span class="s1">&#39;bridge&#39;</span>/&gt;
      &lt;model <span class="nv">type</span><span class="o">=</span><span class="s1">&#39;virtio&#39;</span>/&gt;
      &lt;driver <span class="nv">name</span><span class="o">=</span><span class="s1">&#39;vhost&#39;</span> <span class="nv">txmode</span><span class="o">=</span><span class="s1">&#39;iothread&#39;</span> <span class="nv">ioeventfd</span><span class="o">=</span><span class="s1">&#39;on&#39;</span> <span class="nv">event_idx</span><span class="o">=</span><span class="s1">&#39;off&#39;</span> <span class="nv">queues</span><span class="o">=</span><span class="s1">&#39;16&#39;</span>&gt;
        &lt;host <span class="nv">csum</span><span class="o">=</span><span class="s1">&#39;off&#39;</span> <span class="nv">gso</span><span class="o">=</span><span class="s1">&#39;off&#39;</span> <span class="nv">tso4</span><span class="o">=</span><span class="s1">&#39;off&#39;</span> <span class="nv">tso6</span><span class="o">=</span><span class="s1">&#39;off&#39;</span> <span class="nv">ecn</span><span class="o">=</span><span class="s1">&#39;off&#39;</span> <span class="nv">ufo</span><span class="o">=</span><span class="s1">&#39;off&#39;</span> <span class="nv">mrg_rxbuf</span><span class="o">=</span><span class="s1">&#39;off&#39;</span>/&gt;
        &lt;guest <span class="nv">csum</span><span class="o">=</span><span class="s1">&#39;off&#39;</span> <span class="nv">tso4</span><span class="o">=</span><span class="s1">&#39;off&#39;</span> <span class="nv">tso6</span><span class="o">=</span><span class="s1">&#39;off&#39;</span> <span class="nv">ecn</span><span class="o">=</span><span class="s1">&#39;off&#39;</span> <span class="nv">ufo</span><span class="o">=</span><span class="s1">&#39;off&#39;</span>/&gt;
      &lt;/driver&gt;
      &lt;address <span class="nv">type</span><span class="o">=</span><span class="s1">&#39;pci&#39;</span> <span class="nv">domain</span><span class="o">=</span><span class="s1">&#39;0x0000&#39;</span> <span class="nv">bus</span><span class="o">=</span><span class="s1">&#39;0x00&#39;</span> <span class="nv">slot</span><span class="o">=</span><span class="s1">&#39;0x03&#39;</span> <span class="k">function</span><span class="o">=</span><span class="s1">&#39;0x0&#39;</span>/&gt;
    &lt;/interface&gt;
...
</code></pre></td></tr></table>
</div>
</div><p>启动虚拟机后，在宿主机上可以看到对应的 macvtap 设备被创建，其 mac 地址也与配置中的一致。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">$ ip a
...
5: eth3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class="m">1500</span> qdisc mq state UP group default qlen <span class="m">1000</span>
    link/ether a4:dc:be:0a:7d:37 brd ff:ff:ff:ff:ff:ff
    inet 192.168.1.107/24 brd 192.168.1.255 scope global eth3
       valid_lft forever preferred_lft forever
10: macvtap0@eth3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class="m">1500</span> qdisc pfifo_fast state UP group default qlen <span class="m">500</span>
    link/ether 50:54:00:87:bc:c3 brd ff:ff:ff:ff:ff:ff
</code></pre></td></tr></table>
</div>
</div><p>在虚拟机内部，可以看到对应的虚拟网卡，通过 dhcp 上层路由器获取 IP，可以发现，其网关就是宿主机的网关，其网段与宿主机一致。因此，使用 macvtap 相当于让虚拟机与宿主机处于同一个二层。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="o">[</span>root@localhost ~<span class="o">]</span><span class="c1"># dhclient -v eth0</span>
...
Listening on LPF/eth0/50:54:00:87:bc:c3
Sending on   LPF/eth0/50:54:00:87:bc:c3
Sending on   Socket/fallback
DHCPREQUEST on eth0 to 255.255.255.255 port <span class="m">67</span> <span class="o">(</span><span class="nv">xid</span><span class="o">=</span>0x4e586341<span class="o">)</span>
DHCPNAK from 192.168.1.1 <span class="o">(</span><span class="nv">xid</span><span class="o">=</span>0x4e586341<span class="o">)</span>
DHCPDISCOVER on eth0 to 255.255.255.255 port <span class="m">67</span> interval <span class="m">8</span> <span class="o">(</span><span class="nv">xid</span><span class="o">=</span>0x1d605c78<span class="o">)</span>
DHCPREQUEST on eth0 to 255.255.255.255 port <span class="m">67</span> <span class="o">(</span><span class="nv">xid</span><span class="o">=</span>0x1d605c78<span class="o">)</span>
DHCPOFFER from 192.168.1.1
DHCPACK from 192.168.1.1 <span class="o">(</span><span class="nv">xid</span><span class="o">=</span>0x1d605c78<span class="o">)</span>
bound to 192.168.1.105 -- renewal in <span class="m">3423</span> seconds.

<span class="o">[</span>root@localhost ~<span class="o">]</span><span class="c1"># ip a</span>
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class="m">1500</span> qdisc mq state UP group default qlen <span class="m">1000</span>
    link/ether 52:54:00:87:bc:c1 brd ff:ff:ff:ff:ff:ff
    inet 192.168.1.105/24 brd 192.168.1.255 scope global dynamic eth0
       valid_lft 7023sec preferred_lft 7023sec
</code></pre></td></tr></table>
</div>
</div><h3 id="43-设备直接分配">4.3 设备直接分配</h3>
<p>前面的各种网络模式，最后还是靠着全虚拟化或者半虚拟化将数据包传递给虚拟机，而如果你有着多个可用的网卡，那么可以考虑使用设备直接分配，这是性能最高的方式。</p>
<h4 id="431-pci-网卡">4.3.1 PCI 网卡</h4>
<p>在设备 xml 配置文件中添加 <strong>&lt;hostdev&gt;</strong> 项，指定对应的设备 PCI 地址，来直接分配设备（也可以使用 <strong>&lt;interface type=&lsquo;hostdev&rsquo;/&gt;</strong>，这是一种 libvirt 提供的较新的配置方式，但是不兼容所有设备）。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">…
    &lt;hostdev <span class="nv">mode</span><span class="o">=</span><span class="s1">&#39;subsystem&#39;</span> <span class="nv">type</span><span class="o">=</span><span class="s1">&#39;pci&#39;</span> <span class="nv">managed</span><span class="o">=</span><span class="s1">&#39;yes&#39;</span>&gt;
        &lt;source&gt;
            &lt;address <span class="nv">domain</span><span class="o">=</span><span class="s1">&#39;0x0000&#39;</span> <span class="nv">bus</span><span class="o">=</span><span class="s1">&#39;0x01&#39;</span> <span class="nv">slot</span><span class="o">=</span><span class="s1">&#39;0x00&#39;</span> <span class="k">function</span><span class="o">=</span><span class="s1">&#39;0x0&#39;</span>/&gt;
        &lt;/source&gt;
    &lt;/hostdev&gt;
…
</code></pre></td></tr></table>
</div>
</div><p>启动虚拟机后，在宿主机上就无法看到对应的网卡了，因为对应的驱动被 libvirt 解绑了。
关闭虚拟机后，libvirt 又会重新将网卡绑定驱动，在宿主机上有可见了。</p>
<h4 id="431-sr-iov">4.3.1 SR-IOV</h4>
<p>TODO</p>
<h2 id="参考">参考</h2>
<ul>
<li><a href="https://libvirt.org/formatdomain.html#hard-drives-floppy-disks-cdroms" target="_blank" rel="noopener noreffer">libvirt domain 配置官方文档</a></li>
<li><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/virtualization_deployment_and_administration_guide/chap-Guest_virtual_machine_device_configuration" target="_blank" rel="noopener noreffer">RedHat：Guest Virtual Machine Device Configuration</a></li>
<li><a href="https://wiki.openstack.org/wiki/Raw-device-mapping-support#Virtio-scsi_Passthrough" target="_blank" rel="noopener noreffer">virtio-scsi passthrough</a></li>
<li><a href="https://blog.csdn.net/yongwan5637/article/details/91489961" target="_blank" rel="noopener noreffer">virtio-scsi 和 virtio-blk 的理解</a></li>
<li><a href="https://wiki.libvirt.org/page/Networking" target="_blank" rel="noopener noreffer">libvirt: Networking</a></li>
<li><a href="https://wiki.libvirt.org/page/VirtualNetworking#The_default_configuration" target="_blank" rel="noopener noreffer">libvirt: VirtualNetworking</a></li>
</ul>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>更新于 2020-11-28</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"><span>
                            <a class="link-to-markdown" href="/posts/cloud/vm/kvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E5%AD%98%E5%82%A8%E4%B8%8E%E7%BD%91%E7%BB%9C/index.md" target="_blank">阅读原始文档</a>
                        </span></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="分享到 Twitter" data-sharer="twitter" data-url="https://KanShiori.github.io/posts/cloud/vm/kvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E5%AD%98%E5%82%A8%E4%B8%8E%E7%BD%91%E7%BB%9C/" data-title="KVM 虚拟机的存储与网络总结" data-hashtags="虚拟机,KVM,云计算"><i class="fab fa-twitter fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="分享到 Facebook" data-sharer="facebook" data-url="https://KanShiori.github.io/posts/cloud/vm/kvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E5%AD%98%E5%82%A8%E4%B8%8E%E7%BD%91%E7%BB%9C/" data-hashtag="虚拟机"><i class="fab fa-facebook-square fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="分享到 Hacker News" data-sharer="hackernews" data-url="https://KanShiori.github.io/posts/cloud/vm/kvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E5%AD%98%E5%82%A8%E4%B8%8E%E7%BD%91%E7%BB%9C/" data-title="KVM 虚拟机的存储与网络总结"><i class="fab fa-hacker-news fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="分享到 Line" data-sharer="line" data-url="https://KanShiori.github.io/posts/cloud/vm/kvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E5%AD%98%E5%82%A8%E4%B8%8E%E7%BD%91%E7%BB%9C/" data-title="KVM 虚拟机的存储与网络总结"><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@6.20.0/icons/line.svg" aria-hidden="true"></i></a><a href="javascript:void(0);" title="分享到 微博" data-sharer="weibo" data-url="https://KanShiori.github.io/posts/cloud/vm/kvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E5%AD%98%E5%82%A8%E4%B8%8E%E7%BD%91%E7%BB%9C/" data-title="KVM 虚拟机的存储与网络总结"><i class="fab fa-weibo fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="分享到 百度" data-sharer="baidu" data-url="https://KanShiori.github.io/posts/cloud/vm/kvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E5%AD%98%E5%82%A8%E4%B8%8E%E7%BD%91%E7%BB%9C/" data-title="KVM 虚拟机的存储与网络总结"><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@6.20.0/icons/baidu.svg" aria-hidden="true"></i></a><a href="javascript:void(0);" title="分享到 Evernote" data-sharer="evernote" data-url="https://KanShiori.github.io/posts/cloud/vm/kvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E5%AD%98%E5%82%A8%E4%B8%8E%E7%BD%91%E7%BB%9C/" data-title="KVM 虚拟机的存储与网络总结"><i class="fab fa-evernote fa-fw" aria-hidden="true"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/">虚拟机</a>,&nbsp;<a href="/tags/kvm/">KVM</a>,&nbsp;<a href="/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/">云计算</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/posts/cloud/cloud_native/docker/how_docker_work/container-start-stop-summary/" class="prev" rel="prev" title="容器启停原理总结"><i class="fas fa-angle-left fa-fw" aria-hidden="true"></i>容器启停原理总结</a>
            <a href="/posts/language/golang/language/memory-manager/" class="next" rel="next" title="Go 内存管理总结">Go 内存管理总结<i class="fas fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
</article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line" itemscope itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw" aria-hidden="true"></i><span itemprop="copyrightYear">2020 - 2023</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank">Shiori</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="回到顶部">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="查看评论">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.1/dist/autocomplete.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/algoliasearch@4.13.0/dist/algoliasearch-lite.umd.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.1/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"复制到剪贴板","maxShownLines":35},"comment":{},"search":{"algoliaAppID":"9NJS0VQU0I","algoliaIndex":"blog","algoliaSearchKey":"85d62ea65a7f7445fbfb413bdca088f2","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
