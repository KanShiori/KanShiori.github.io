[{"categories":["k8s 实践"],"content":"使用 StatefulSet 进行副本控制","date":"2020-10-30","objectID":"/statefulset-%E5%AE%9E%E8%B7%B5/","tags":["k8s","云计算"],"title":"StatefulSet 实践","uri":"/statefulset-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"Deployment 对于“无状态”的任务，已经能够做到副本控制，滚动升级功能了。但是 Deployment 无法适用于“有状态”的任务，因为其中 Pod 都是相同的，没有任何的对应关系。 而 StatefulSet 通过“固定命名、域名的 Pod，以及固定的创建顺序”作为基础，加上与命名对应的网络、存储，搭建一个“有状态”Pod 管理。 ","date":"2020-10-30","objectID":"/statefulset-%E5%AE%9E%E8%B7%B5/:0:0","tags":["k8s","云计算"],"title":"StatefulSet 实践","uri":"/statefulset-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"1 HeadlessService StatefulSet 会使用 HeadlessService 的概念，首先来部署 HeadlessService。 创建描述文件 headless_service 可以看到，Headless 与普通 Service 最大区别是 clusterIP 为 None。 通过 kubectl create 部署 HeadlessService，成功后可以看到： 查看 Endpoint，可对应的 Endpoint 包含了 Node-1 Node-2 的 Pod 的地址了。并且 Endpoint 命名和Service 名字一样。 你按照这样的方式创建了一个 Headless Service 之后，它所代理的所有 Pod 的 IP 地址，都会被绑定一个这样格式的 DNS 记录： \u003cpod-name\u003e.\u003csvc-name\u003e.\u003cnamespace\u003e.svc.cluster.local 但是好像单独使用 Headless Service 是无法访问这些域名的。 ","date":"2020-10-30","objectID":"/statefulset-%E5%AE%9E%E8%B7%B5/:1:0","tags":["k8s","云计算"],"title":"StatefulSet 实践","uri":"/statefulset-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"2 StatfulSet ","date":"2020-10-30","objectID":"/statefulset-%E5%AE%9E%E8%B7%B5/:2:0","tags":["k8s","云计算"],"title":"StatefulSet 实践","uri":"/statefulset-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"2.1 StaefulSet 的固定域名 下面开始部署 StatefulSet： 先要创建对应的 Headless Service，如前面一样。 创建对应的 StatefulSet 描述文件： 可以看到，StatefulSet 与 Deployment 最大的区别就是指定了 serviceName 字段，指定了使用的 HeadlessService。 创建 StatefulSet 对象，类似于 Deployment，开始创建 Pod 了 但是 StatefulSet 并没有创建任何的 ReplicaSet，所以实现上与 Deployment 不一样： 观察创建出的 Pod，可以看到，其 Pod 命名不是加上随机字符串了，而是有序的数字： 并且，其创建顺序也是有序的，先创建 web-0 ，web-0 运行后并 Ready 后，创建 web-1。 运行一个 busybox 测试容器，执行 nslookup 访问 HeadlessService 为其绑定的域名，可以看到正常返回了。 删除 web-0 Pod，可以看到 StatefulSet 会重新立刻创建同名的 Pod。所以，Pod 名字是固定的 再次通过 web-0.nginx.default.svc.cluster.local 进行域名解析，还是能够正确的解析： 注意：虽然域名可以正确解析，但是其域名对应的 IP 不是保证固定的，所以不能保存 Pod 的 IP ","date":"2020-10-30","objectID":"/statefulset-%E5%AE%9E%E8%B7%B5/:2:1","tags":["k8s","云计算"],"title":"StatefulSet 实践","uri":"/statefulset-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"2.2 StatefulSet 的固定存储 目的：使用 StatefulSet 中的 Template PVC 自动构建持久化存储，并观察其 PVC 是否与 PodName 绑定。 构建 nfs 的 2 个 PV，给 2 个 Pod 准备。（构建过程见\u003cPV、PVC 与 StorageClass\u003e一节） 创建 StatefulSet，其指定 PVC 模板，使得能够为每个 Pod 自动创建其对应的 PVC。 创建后可以看到，StatefulSet 为 2 个 Pod 创建了对应的 PVC： 可以看到，PVC 是和名字对应的，格式为 [volume name]-[pod name]，因此，PVC 与 Pod 名字的映射关系是固定的。 所以这就实现了，当旧 Pod 删除，新 Pod 被创建后，因为其 Pod Name 没有变，所以就找到了旧 Pod 使用 PVC。 ","date":"2020-10-30","objectID":"/statefulset-%E5%AE%9E%E8%B7%B5/:2:2","tags":["k8s","云计算"],"title":"StatefulSet 实践","uri":"/statefulset-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"使用 Deployment 进行部署","date":"2020-10-16","objectID":"/deployment-%E5%AE%9E%E8%B7%B5/","tags":["k8s","云计算"],"title":"Deployment 实践","uri":"/deployment-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"1 ReplicaSet Deploment 管理的是 ReplicaSet，所以先运行 ReplicaSet 观察。 ReplicaSet 只包含副本控制功能，没有滚动升级等高级的功能。 ","date":"2020-10-16","objectID":"/deployment-%E5%AE%9E%E8%B7%B5/:1:0","tags":["k8s","云计算"],"title":"Deployment 实践","uri":"/deployment-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"1.1 部署 ReplicaSet 创建 manifest 文件。 调用 kubectl create 创建资源。 观察下 ReplicaSet 的事件，可以看到各个 Pod 的创建流程。 ","date":"2020-10-16","objectID":"/deployment-%E5%AE%9E%E8%B7%B5/:1:1","tags":["k8s","云计算"],"title":"Deployment 实践","uri":"/deployment-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"1.2 副本保证 目前，3 个 Pod 都运行在了 Node-3 上： 下线 Node-3 ，可以看到 node-3 变为 NotReady: 过了一段时间后，原来三个 Pod 变为 Terminating 状态，而新的 Pod 被创建被调度。 可以看到，新创建 3 个 Pod 被调度到了 Node-2 上: 恢复 Node-3 上线，kubelet 会同步任务，因此不会再次运行旧的三个 Pod。Pod 的状态也从 Terminating 变为被删除。 ","date":"2020-10-16","objectID":"/deployment-%E5%AE%9E%E8%B7%B5/:1:2","tags":["k8s","云计算"],"title":"Deployment 实践","uri":"/deployment-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"1.3 水平缩扩 通过 kubectl scale 进行副本扩展: 可以看到，新的 Pod 在 Node-3 被运行： 依旧 kubectl scale 进行副本缩容，可以看到，两个 Pod 被停止: 可以看到，ReplicaSet 启动和停止任务都是由 Scheduler 选择的，而不能认为的控制选择指定的 Pod，也就是说，所有的 Pod 应该被认为是“无状态的”，随时可能被停止。 ","date":"2020-10-16","objectID":"/deployment-%E5%AE%9E%E8%B7%B5/:1:3","tags":["k8s","云计算"],"title":"Deployment 实践","uri":"/deployment-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"2 Deployment Deployment 操作与管理的是 ReplicaSet，而不是 Pod。 ","date":"2020-10-16","objectID":"/deployment-%E5%AE%9E%E8%B7%B5/:2:0","tags":["k8s","云计算"],"title":"Deployment 实践","uri":"/deployment-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"2.1 部署 构建 manfiest 文件: 通过 kubectl create 创建 Deployment。 可以看到，Event 中打印的是对应的ReplicaSet 的自动被创建，所以Deployment 是创建 ReplicaSet 的。 ","date":"2020-10-16","objectID":"/deployment-%E5%AE%9E%E8%B7%B5/:2:1","tags":["k8s","云计算"],"title":"Deployment 实践","uri":"/deployment-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"2.2 水平扩展 Deployment 水平扩展方式与 ReplicaSet 一致，并且就是操作 ReplicaSet 的 replica 的值来实现，跳过。 ","date":"2020-10-16","objectID":"/deployment-%E5%AE%9E%E8%B7%B5/:2:2","tags":["k8s","云计算"],"title":"Deployment 实践","uri":"/deployment-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"2.3 滚动升级 (1) 正常流程 Deployment 在 ReplicaSet 基础上添加了“滚动升级”的功能。 依旧创建 Deployment，并直接扩展到副本数为 3。 修改 Deployment 的配置文件，将 image 版本升级。 可以看到，Deployment 新建了一个 ReplicaSet （部署新版本 Pod），而旧的 ReplicaSet 副本变为了 0。 通过 Deployment 的 Event 可以看到，旧版 ReplicaSet 的副本数逐渐减少，而新版本 ReplicaSet 副本数逐渐增加。这样使得集群中 Pod 会维持在一个最低数量（示例中为 3） (2) 错误流程 观察下当升级出现错误时，Deployment 会处于怎样的状态。 通过 kubectl set image 将 Deployment 使用镜像变为一个不存在的镜像。 通过 Event 看到，滚动升级停止在了最新版本的 Replicaset 的第一个副本部署。 因为新旧版本是交替部署的，所以当第一个副本部署失败时，也就不会继续进行旧版本 Pod 的停止了。 ","date":"2020-10-16","objectID":"/deployment-%E5%AE%9E%E8%B7%B5/:2:3","tags":["k8s","云计算"],"title":"Deployment 实践","uri":"/deployment-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"2.4 回滚 在错误流程看到，当发布错误的版本后，Deployment 会停止新版本的发布，而这时，就需要通过 kubectl rollout 进行 Deployment 的回滚。 执行 kubectl rollout history，查看每次 Deployment 变更对应的版本。（因为 -record，所有的 kubectl 命令都会被记录）。 可以看到，两次的版本变更都被记录了下来。 通过 –revision 参数，查看对应的命令细节。 通过 kubectl rollout undo 进行版本的回退，默认为上一次版本，通过 –to-revision 可以执行回退的版本。 事实上，回退也是一次“升级”，通过 history 可以看到一个新的部署记录： 这个 4，就是最新的一次回滚执行的命令了。 ","date":"2020-10-16","objectID":"/deployment-%E5%AE%9E%E8%B7%B5/:2:4","tags":["k8s","云计算"],"title":"Deployment 实践","uri":"/deployment-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"单机使用虚拟机搭建 k8s 集群","date":"2020-10-15","objectID":"/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/","tags":["k8s","云计算"],"title":"虚拟机 k8s 集群搭建","uri":"/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["k8s 实践"],"content":"1 虚拟机集群搭建 目标：创建 3 个虚拟机，用作一个 Master Node，两个 Work Node；当然，三个节点处于同一个网段。 具体步骤如下: 构建节点 构建三个虚拟机，基于 centos 7、内存 2 GB，并通过虚拟机复制功能（其实就是 copy 系统盘），完全复制出 Node 1，Node 2，Node 3。 搭建网络 三个节点需要互相访问，所以将其位于 VirtualBox 创建的 Nat网络下，给予每个 Node 静态的 IP（10.0.2.10 - 10.0.2.12），为了方便访问，并设置 ssh 的 DNAT。 设置每个虚拟机网卡加入其创建的 “NodeNatNetwork”。例如： 启动每个虚拟机，设置其 hostname，与网卡静态 IP。例如： 至此，三个虚拟机位于同一个网段，并且能够相互访问；对外，则通过 VirtualBox 的 Nat 网络能够访问。 ","date":"2020-10-15","objectID":"/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:1:0","tags":["k8s","云计算"],"title":"虚拟机 k8s 集群搭建","uri":"/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["k8s 实践"],"content":"2 部署 K8s 目标：通过 kubeadm 部署整个 k8s，用 Node-1 为 Master 节点，其他为工作节点。 ","date":"2020-10-15","objectID":"/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:2:0","tags":["k8s","云计算"],"title":"虚拟机 k8s 集群搭建","uri":"/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["k8s 实践"],"content":"2.1 安装 kubeadm、kubelet、kubectl 安装 kubeadm、kubelet、kubectl。这个官方文档写的很详细，见 Installing kubeadm 。 ","date":"2020-10-15","objectID":"/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:2:1","tags":["k8s","云计算"],"title":"虚拟机 k8s 集群搭建","uri":"/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["k8s 实践"],"content":"2.2 kubeadm init 初始化 Master 节点 Node-1 节点执行 kubeadm init，将其作为 Master 节点初始化。执行成功后，kubeadm 生成了 Kubernetes 组件的各个配置，以及提供服务的各类证书，位于 /etc/kubernetes 目录下: 并且已经以 static pod 的形式启动了：apiserver、controller-manager、etcd、scheduler。 还有最重要的，kubeadm 为集群生成一个【bootstrap token】，需要加入集群的节点都需要通过这个 token 加入。 * 问题 kubeadm 检查 swap 打开着，kubeadm 推荐不使用 swap，通过 swapoff -a 关闭交换区。 kubectl 默认通过 8080 端口访问，无法执行。 设置 kubectl 的配置文件为 kubeadm 生成的 /etc/kubernetes/admin.conf。（其实就是配置公钥，或者将 admin.conf 移动到 ~/.kube/config 文件，作为默认配置。 ","date":"2020-10-15","objectID":"/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:2:2","tags":["k8s","云计算"],"title":"虚拟机 k8s 集群搭建","uri":"/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["k8s 实践"],"content":"2.3 kubeadm join [token] 设置工作节点 通过 kubead init 最后返回的提示信息，执行对应 kubeadm join 将 Node-1 Node-2 加入到集群中，作为工作节点。 [root@Node-2 kubeadm join 10.0.2.10:6443 --token mahrou.d3uodof21i3d6yxk --discovery-token-ca-cert-hash sha256:21dfe4ef6b3bbd89f803bf44ff6eda587874336d103d0e4a3b --v 5 可以看到，kubelet 启动后就通过 pod 方式启动了本节点上 kube-proxy 容器： * 问题 无法访问到 Node-1 节点，nc ip 失败，但是可以 ping 通。通过在 Node-1 tcpdump 可以抓取到来自 Node-3 的包，因此应该是防火墙的问题，通过 iptables 对 Node-2 Node-3 IP 开放。 kubectl 无法访问问题，与上述问题一致。 ","date":"2020-10-15","objectID":"/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:2:3","tags":["k8s","云计算"],"title":"虚拟机 k8s 集群搭建","uri":"/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["k8s 实践"],"content":"2.4 结果 目前为止，就完成了集群的搭建，但是 通过 kubectl get nodes，可以看到所有节点都是 NotReady： kubectl describe node node-1 可以看到，原因是因为没有设置正确的 Network Plugin： ","date":"2020-10-15","objectID":"/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:2:4","tags":["k8s","云计算"],"title":"虚拟机 k8s 集群搭建","uri":"/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["k8s 实践"],"content":"3 部署网络插件 目的：部署网络插件，使各个节点为 Ready 状态，并其内部 Pod 能够相互通信。 以 Weave 部署为例，部署网络插件： kubectl apply -f \"https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\\n')\" 其描述文件中定义所有 Weave 需要的 BAAC 权限组件，以及最重要的网络插件 Pod 对应的 DaemonSet: 应用成功后，可以看到对应的 DaemonSet 就运行起来，并开始给三个 Node 部署 Pod: 在节点上，可以看到 weave-net 对应的 pod ，包括两个容器： ","date":"2020-10-15","objectID":"/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:3:0","tags":["k8s","云计算"],"title":"虚拟机 k8s 集群搭建","uri":"/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["k8s 实践"],"content":"4 部署容器存储插件 目的：为了能够让容器使用网络存储，使得容器数据持久化，需要部署存储插件。 以 Rook 项目为例，部署存储插件： $ kubectl apply -f https://raw.githubusercontent.com/rook/rook/master/cluster/exampleskubernetes/ceph/common.yaml $ kubectl apply -f https://raw.githubusercontent.com/rook/rook/master/cluster/exampleskubernetes/ceph/operator.yaml $ kubectl apply -f https://raw.githubusercontent.com/rook/rook/master/cluster/examples/kubernetes/ceph/cluster.yaml 安装成功后，可以看到，rook 有着自己的 namespace，并且已经部署了 DaemonSet： 可以看到，Pod 也部署成功了： ","date":"2020-10-15","objectID":"/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:4:0","tags":["k8s","云计算"],"title":"虚拟机 k8s 集群搭建","uri":"/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":null,"content":"博客使用 Hugo 框架进行搭建, 主题使用 hugo-clarity. Logo 由 gopherize.me 生成. ","date":"2020-10-15","objectID":"/about/:0:0","tags":null,"title":"关于","uri":"/about/"}]