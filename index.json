[{"categories":["k8s 实践"],"content":"使用 PV 与 PVC 为 Pod 提供存储","date":"2020-10-30","objectID":"/posts/cloud_computing/k8s_practice/pv-pvc-%E4%B8%8E-storageclass/","tags":["k8s","云计算"],"title":"PV PVC 与 StorageClass","uri":"/posts/cloud_computing/k8s_practice/pv-pvc-%E4%B8%8E-storageclass/"},{"categories":["k8s 实践"],"content":"1 PV 与 PVC 目的：使用 NFS 做 PV，创建 Pod 使用该 PV Node-1 构建 nfs 服务，位于 “/nfs” 目录。 创建 PV，使用 nfs 类型。 声明、创建 PVC，使用上述指定的 StorageClass，形成指定的绑定关系。 pvc 状态为 Bound，表明已经成功绑定到了 pvc。查询 pv，可以看到 pv 也是被绑定了。(注意：一个 PV 只能绑定一个 PV) 创建 Pod Deployment，在 Pod 的 Volume 使用 PVC。 其中两个 Pod 分别调度到了 Node-2 Node-3，在 Node-2 Node-3 中可以看到对应的 nfs mount： 对应容器配置也可以看到指定的挂载： 在 Node-3 节点的容器环境内写入挂载路径文件，可以看到同步到了主节点的 /nfs 目录上，因此，存储配置成功。 ","date":"2020-10-30","objectID":"/posts/cloud_computing/k8s_practice/pv-pvc-%E4%B8%8E-storageclass/:1:0","tags":["k8s","云计算"],"title":"PV PVC 与 StorageClass","uri":"/posts/cloud_computing/k8s_practice/pv-pvc-%E4%B8%8E-storageclass/"},{"categories":["k8s 实践"],"content":"使用 RBAC 进行访问控制与授权","date":"2020-10-30","objectID":"/posts/cloud_computing/k8s_practice/rbac-%E5%AE%9E%E8%B7%B5/","tags":["k8s","云计算"],"title":"RBAC 实践","uri":"/posts/cloud_computing/k8s_practice/rbac-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"Kubernetes 中，通过 RBAC 机制来实现集群 Pod 中对 APIServer 的访问权限控制与授权。 RBAC 机制有三个最基本的概念： Role：一组规则，定义了对 API 对象的操作权限； Subject：被作用者，集群内部常常使用的是 ServiceAccount； RoleBinding：绑定 Role 与 Subject； ","date":"2020-10-30","objectID":"/posts/cloud_computing/k8s_practice/rbac-%E5%AE%9E%E8%B7%B5/:0:0","tags":["k8s","云计算"],"title":"RBAC 实践","uri":"/posts/cloud_computing/k8s_practice/rbac-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"1 Role 与 ServiceAccount 实践 目的：通过 Role 与 RoleBinding 限制一类 ServiceAccount，并在 Pod 中使用该 ServiceAccount 观察权限控制。 创建需要使用的自定义 namespace [mynamespace] 创建需要限制访问权限的 ServiceAccount [example-sa] 可以看到，每个 namespace 有个默认的 ServiceAccount default，提供完整的 APIServer 访问权限。 每个 ServiceAccount 在容器维度看到就是 Secret 对象，包含证书内容。 创建 Role，定义允许的权限规则。 可以看到，rules 指定了该 Role 为：允许对 mynamespace 下的 pod 进行 get、watch、list 操作。 创建 RoleBinding，关联刚刚创建的 Role 与 ServiceAccount。 创建 Pod，指定使用的 ServiceAccount，在 Pod 内观察权限是否被限制了 进入容器中，可以看到，k8s 将 ServiceAccount 对应的 Serects 对象挂载到了 /run/secrets/kubernetes.io/serviceaccount 目录下，包含 client 需要使用的【证书 ca.crt】、【token】: ","date":"2020-10-30","objectID":"/posts/cloud_computing/k8s_practice/rbac-%E5%AE%9E%E8%B7%B5/:1:0","tags":["k8s","云计算"],"title":"RBAC 实践","uri":"/posts/cloud_computing/k8s_practice/rbac-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"使用 CRD 自定义资源，通过 Kubernetes 编排","date":"2020-10-30","objectID":"/posts/cloud_computing/k8s_practice/crd-%E5%AE%9E%E8%B7%B5/","tags":["k8s","云计算"],"title":"CRD 实践","uri":"/posts/cloud_computing/k8s_practice/crd-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"CRD 是 Kubernetes 可扩展性的第一个体现，因为 Kubernetes 提供的是一个编排的框架，因此不止可以对 Pod 进行编排，也支持通过 CRD 对你自定义的类型的编排。 ","date":"2020-10-30","objectID":"/posts/cloud_computing/k8s_practice/crd-%E5%AE%9E%E8%B7%B5/:0:0","tags":["k8s","云计算"],"title":"CRD 实践","uri":"/posts/cloud_computing/k8s_practice/crd-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"1 CRD 构建 目的：通过 CRD 构建一个自定义资源。 编写 CRD manifest，完成自定义资源的定义。 可以看到，CRD 中只有类型的简单定义，没有该 CR 的元属性的定义，因为这些需要通过代码中定义。 通过 kubectl apply 创建 CR 对应 CRD 对象，让 Kubernetes “认识” 这个自定义资源。 调用 kubectl apply 创建自定义资源： 这里其实 Kubernetes 不知道该资源具体的代码类型，它只是知道有 CRNetwork 这个资源，并支持创建删除，将其保存下来了。 编写 CR 相关定义代码。其实这里编写代码是为生成 kubectl 的 Client，使其在编写 Controller 时候能够正确的解析你的 CR 对象。 整个的目录结构如下： 具体代码见仓库：k8s_practice 通过 k8s 生成代码，最终生成的目录结构如下： ","date":"2020-10-30","objectID":"/posts/cloud_computing/k8s_practice/crd-%E5%AE%9E%E8%B7%B5/:1:0","tags":["k8s","云计算"],"title":"CRD 实践","uri":"/posts/cloud_computing/k8s_practice/crd-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"2 编写自定义控制器 因为 Kubernetes 中是基于声明式 API 的业务实现，所以需要控制器来“监控”对象变化，执行对应的操作。 编写自动以控制器主要有三个过程：编写 main 函数、编写自定义控制器定义，编写控制器业务逻辑。 整个实践代码见：k8s_practice Controller 代码编写。主要逻辑：处理 Informer 通知的 Event，执行 CR Sync 操作。 Controller 主要包含三个部分： Informer：包含从 APIServer 同步的 CR 对象的 Cache，并且处理 CR Event，调用 Event Handler。 Event Handler：Informer 的各个 Event 调用的事件回调，一般都是放入 workQueue，延后处理。 Workers：根据各个 Event 进行真正的业务处理，例如真实资源的创建、删除、更新等。 main 函数代码编写。主要逻辑：创建 Informer、Controller，执行 Controller 的启动。 编译后运行 Controller。 第一同步后，所有的 CR 对象都可以被任务是“新添加的”，因此会一个个调用 HandleAdd 接口。上图可以看到，因为集群中已经有了一个 CR 对象，因此 Controller 会进行该对象的 Sync。 创建一个新的 CR 对象 example-crnetwork-2，观察 Controller。 可以看到 Controller 处理完成。 删除刚创建的 example-crnetwork-2，观察 Controller。 可以看到 Controller 正确的执行删除的逻辑。 ","date":"2020-10-30","objectID":"/posts/cloud_computing/k8s_practice/crd-%E5%AE%9E%E8%B7%B5/:2:0","tags":["k8s","云计算"],"title":"CRD 实践","uri":"/posts/cloud_computing/k8s_practice/crd-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"3 将自定义资源控制封装为 Pod TODO ","date":"2020-10-30","objectID":"/posts/cloud_computing/k8s_practice/crd-%E5%AE%9E%E8%B7%B5/:3:0","tags":["k8s","云计算"],"title":"CRD 实践","uri":"/posts/cloud_computing/k8s_practice/crd-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"使用 Job 或者 CronJob 部署一次性任务","date":"2020-10-30","objectID":"/posts/cloud_computing/k8s_practice/job-cronjob-%E5%AE%9E%E8%B7%B5/","tags":["k8s","云计算"],"title":"Job CronJob 实践","uri":"/posts/cloud_computing/k8s_practice/job-cronjob-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"Job 用于运行一次性的任务，即“离线任务”。CronJob 在 Job 之上提供了周期性任务支持。 ","date":"2020-10-30","objectID":"/posts/cloud_computing/k8s_practice/job-cronjob-%E5%AE%9E%E8%B7%B5/:0:0","tags":["k8s","云计算"],"title":"Job CronJob 实践","uri":"/posts/cloud_computing/k8s_practice/job-cronjob-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"1 Job 目的：部署 Job 任务，使用并行运行（Batch）的功能。 创建部署 Job 任务。 可以看到，并行的两个 Pod 正在运行。 经过一段时间可以看到，因为设置 deadline 为 100，所以 pod 异常被退出。而 restartPolicy: Never 使得不会再次运行。 去除 deadline 设置，重新部署，可以看到，本次 4 次成功完成。 ","date":"2020-10-30","objectID":"/posts/cloud_computing/k8s_practice/job-cronjob-%E5%AE%9E%E8%B7%B5/:1:0","tags":["k8s","云计算"],"title":"Job CronJob 实践","uri":"/posts/cloud_computing/k8s_practice/job-cronjob-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"2 CronJob 目的：体验 CronJob 的周期性任务功能，明确 CronJob 是基于 Job 管理实现的。 创建部署 CronJob 。可以看到，CronJob 中需要指定 JobTemplate，因此 CronJob 完全是基于 Job 管理的。 部署后可以看到，CronJob 创建了一个 Job： 经过一分钟，新 Job 被创建，并运行成功： ","date":"2020-10-30","objectID":"/posts/cloud_computing/k8s_practice/job-cronjob-%E5%AE%9E%E8%B7%B5/:2:0","tags":["k8s","云计算"],"title":"Job CronJob 实践","uri":"/posts/cloud_computing/k8s_practice/job-cronjob-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"使用 DaemonSet 部署常驻容器","date":"2020-10-30","objectID":"/posts/cloud_computing/k8s_practice/daemonset-%E5%AE%9E%E8%B7%B5/","tags":["k8s","云计算"],"title":"DaemonSet 实践","uri":"/posts/cloud_computing/k8s_practice/daemonset-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"DaemonSet 会为匹配的 Node 运行一个 Daemon Pod，与 Deployment 类最大不同，DaemonSet 没有副本的概念。 目的：部署 DaemonSet，试用 toleration 与 nodeAffinity，观察滚动升级流程。 部署 DaemonSet。其中，是用 nodeAffinity 指定选择调度的节点，使用 toleration 容器 Node 的 taint: 创建后，可以看到，只选择调度到了 node-1 node-2 节点，和配置的 Affinity 匹配： 改变 DaemonSet 使用的镜像版本，观察滚动升级流程: 通过 kubectl rollout status 可以看到，滚动升级流程与 Deployment 过程一致： 观察 Event，可以看到也是按照 delete -\u003e create 的流程进行升级的。 ","date":"2020-10-30","objectID":"/posts/cloud_computing/k8s_practice/daemonset-%E5%AE%9E%E8%B7%B5/:0:0","tags":["k8s","云计算"],"title":"DaemonSet 实践","uri":"/posts/cloud_computing/k8s_practice/daemonset-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"使用 StatefulSet 进行副本控制","date":"2020-10-30","objectID":"/posts/cloud_computing/k8s_practice/statefulset-%E5%AE%9E%E8%B7%B5/","tags":["k8s","云计算"],"title":"StatefulSet 实践","uri":"/posts/cloud_computing/k8s_practice/statefulset-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"Deployment 对于“无状态”的任务，已经能够做到副本控制，滚动升级功能了。但是 Deployment 无法适用于“有状态”的任务，因为其中 Pod 都是相同的，没有任何的对应关系。 而 StatefulSet 通过“固定命名、域名的 Pod，以及固定的创建顺序”作为基础，加上与命名对应的网络、存储，搭建一个“有状态”Pod 管理。 ","date":"2020-10-30","objectID":"/posts/cloud_computing/k8s_practice/statefulset-%E5%AE%9E%E8%B7%B5/:0:0","tags":["k8s","云计算"],"title":"StatefulSet 实践","uri":"/posts/cloud_computing/k8s_practice/statefulset-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"1 HeadlessService StatefulSet 会使用 HeadlessService 的概念，首先来部署 HeadlessService。 创建描述文件 headless_service 可以看到，Headless 与普通 Service 最大区别是 clusterIP 为 None。 通过 kubectl create 部署 HeadlessService，成功后可以看到： 查看 Endpoint，可对应的 Endpoint 包含了 Node-1 Node-2 的 Pod 的地址了。并且 Endpoint 命名和Service 名字一样。 你按照这样的方式创建了一个 Headless Service 之后，它所代理的所有 Pod 的 IP 地址，都会被绑定一个这样格式的 DNS 记录： \u003cpod-name\u003e.\u003csvc-name\u003e.\u003cnamespace\u003e.svc.cluster.local 但是好像单独使用 Headless Service 是无法访问这些域名的。 ","date":"2020-10-30","objectID":"/posts/cloud_computing/k8s_practice/statefulset-%E5%AE%9E%E8%B7%B5/:1:0","tags":["k8s","云计算"],"title":"StatefulSet 实践","uri":"/posts/cloud_computing/k8s_practice/statefulset-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"2 StatfulSet ","date":"2020-10-30","objectID":"/posts/cloud_computing/k8s_practice/statefulset-%E5%AE%9E%E8%B7%B5/:2:0","tags":["k8s","云计算"],"title":"StatefulSet 实践","uri":"/posts/cloud_computing/k8s_practice/statefulset-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"2.1 StaefulSet 的固定域名 下面开始部署 StatefulSet： 先要创建对应的 Headless Service，如前面一样。 创建对应的 StatefulSet 描述文件： 可以看到，StatefulSet 与 Deployment 最大的区别就是指定了 serviceName 字段，指定了使用的 HeadlessService。 创建 StatefulSet 对象，类似于 Deployment，开始创建 Pod 了 但是 StatefulSet 并没有创建任何的 ReplicaSet，所以实现上与 Deployment 不一样： 观察创建出的 Pod，可以看到，其 Pod 命名不是加上随机字符串了，而是有序的数字： 并且，其创建顺序也是有序的，先创建 web-0 ，web-0 运行后并 Ready 后，创建 web-1。 运行一个 busybox 测试容器，执行 nslookup 访问 HeadlessService 为其绑定的域名，可以看到正常返回了。 删除 web-0 Pod，可以看到 StatefulSet 会重新立刻创建同名的 Pod。所以，Pod 名字是固定的 再次通过 web-0.nginx.default.svc.cluster.local 进行域名解析，还是能够正确的解析： 注意：虽然域名可以正确解析，但是其域名对应的 IP 不是保证固定的，所以不能保存 Pod 的 IP ","date":"2020-10-30","objectID":"/posts/cloud_computing/k8s_practice/statefulset-%E5%AE%9E%E8%B7%B5/:2:1","tags":["k8s","云计算"],"title":"StatefulSet 实践","uri":"/posts/cloud_computing/k8s_practice/statefulset-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"2.2 StatefulSet 的固定存储 目的：使用 StatefulSet 中的 Template PVC 自动构建持久化存储，并观察其 PVC 是否与 PodName 绑定。 构建 nfs 的 2 个 PV，给 2 个 Pod 准备。（构建过程见\u003cPV、PVC 与 StorageClass\u003e一节） 创建 StatefulSet，其指定 PVC 模板，使得能够为每个 Pod 自动创建其对应的 PVC。 创建后可以看到，StatefulSet 为 2 个 Pod 创建了对应的 PVC： 可以看到，PVC 是和名字对应的，格式为 [volume name]-[pod name]，因此，PVC 与 Pod 名字的映射关系是固定的。 所以这就实现了，当旧 Pod 删除，新 Pod 被创建后，因为其 Pod Name 没有变，所以就找到了旧 Pod 使用 PVC。 ","date":"2020-10-30","objectID":"/posts/cloud_computing/k8s_practice/statefulset-%E5%AE%9E%E8%B7%B5/:2:2","tags":["k8s","云计算"],"title":"StatefulSet 实践","uri":"/posts/cloud_computing/k8s_practice/statefulset-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"使用 Deployment 进行部署","date":"2020-10-16","objectID":"/posts/cloud_computing/k8s_practice/deployment-%E5%AE%9E%E8%B7%B5/","tags":["k8s","云计算"],"title":"Deployment 实践","uri":"/posts/cloud_computing/k8s_practice/deployment-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"1 ReplicaSet Deploment 管理的是 ReplicaSet，所以先运行 ReplicaSet 观察。 ReplicaSet 只包含副本控制功能，没有滚动升级等高级的功能。 ","date":"2020-10-16","objectID":"/posts/cloud_computing/k8s_practice/deployment-%E5%AE%9E%E8%B7%B5/:1:0","tags":["k8s","云计算"],"title":"Deployment 实践","uri":"/posts/cloud_computing/k8s_practice/deployment-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"1.1 部署 ReplicaSet 创建 manifest 文件。 调用 kubectl create 创建资源。 观察下 ReplicaSet 的事件，可以看到各个 Pod 的创建流程。 ","date":"2020-10-16","objectID":"/posts/cloud_computing/k8s_practice/deployment-%E5%AE%9E%E8%B7%B5/:1:1","tags":["k8s","云计算"],"title":"Deployment 实践","uri":"/posts/cloud_computing/k8s_practice/deployment-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"1.2 副本保证 目前，3 个 Pod 都运行在了 Node-3 上： 下线 Node-3 ，可以看到 node-3 变为 NotReady: 过了一段时间后，原来三个 Pod 变为 Terminating 状态，而新的 Pod 被创建被调度。 可以看到，新创建 3 个 Pod 被调度到了 Node-2 上: 恢复 Node-3 上线，kubelet 会同步任务，因此不会再次运行旧的三个 Pod。Pod 的状态也从 Terminating 变为被删除。 ","date":"2020-10-16","objectID":"/posts/cloud_computing/k8s_practice/deployment-%E5%AE%9E%E8%B7%B5/:1:2","tags":["k8s","云计算"],"title":"Deployment 实践","uri":"/posts/cloud_computing/k8s_practice/deployment-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"1.3 水平缩扩 通过 kubectl scale 进行副本扩展: 可以看到，新的 Pod 在 Node-3 被运行： 依旧 kubectl scale 进行副本缩容，可以看到，两个 Pod 被停止: 可以看到，ReplicaSet 启动和停止任务都是由 Scheduler 选择的，而不能认为的控制选择指定的 Pod，也就是说，所有的 Pod 应该被认为是“无状态的”，随时可能被停止。 ","date":"2020-10-16","objectID":"/posts/cloud_computing/k8s_practice/deployment-%E5%AE%9E%E8%B7%B5/:1:3","tags":["k8s","云计算"],"title":"Deployment 实践","uri":"/posts/cloud_computing/k8s_practice/deployment-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"2 Deployment Deployment 操作与管理的是 ReplicaSet，而不是 Pod。 ","date":"2020-10-16","objectID":"/posts/cloud_computing/k8s_practice/deployment-%E5%AE%9E%E8%B7%B5/:2:0","tags":["k8s","云计算"],"title":"Deployment 实践","uri":"/posts/cloud_computing/k8s_practice/deployment-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"2.1 部署 构建 manfiest 文件: 通过 kubectl create 创建 Deployment。 可以看到，Event 中打印的是对应的ReplicaSet 的自动被创建，所以Deployment 是创建 ReplicaSet 的。 ","date":"2020-10-16","objectID":"/posts/cloud_computing/k8s_practice/deployment-%E5%AE%9E%E8%B7%B5/:2:1","tags":["k8s","云计算"],"title":"Deployment 实践","uri":"/posts/cloud_computing/k8s_practice/deployment-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"2.2 水平扩展 Deployment 水平扩展方式与 ReplicaSet 一致，并且就是操作 ReplicaSet 的 replica 的值来实现，跳过。 ","date":"2020-10-16","objectID":"/posts/cloud_computing/k8s_practice/deployment-%E5%AE%9E%E8%B7%B5/:2:2","tags":["k8s","云计算"],"title":"Deployment 实践","uri":"/posts/cloud_computing/k8s_practice/deployment-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"2.3 滚动升级 (1) 正常流程 Deployment 在 ReplicaSet 基础上添加了“滚动升级”的功能。 依旧创建 Deployment，并直接扩展到副本数为 3。 修改 Deployment 的配置文件，将 image 版本升级。 可以看到，Deployment 新建了一个 ReplicaSet （部署新版本 Pod），而旧的 ReplicaSet 副本变为了 0。 通过 Deployment 的 Event 可以看到，旧版 ReplicaSet 的副本数逐渐减少，而新版本 ReplicaSet 副本数逐渐增加。这样使得集群中 Pod 会维持在一个最低数量（示例中为 3） (2) 错误流程 观察下当升级出现错误时，Deployment 会处于怎样的状态。 通过 kubectl set image 将 Deployment 使用镜像变为一个不存在的镜像。 通过 Event 看到，滚动升级停止在了最新版本的 Replicaset 的第一个副本部署。 因为新旧版本是交替部署的，所以当第一个副本部署失败时，也就不会继续进行旧版本 Pod 的停止了。 ","date":"2020-10-16","objectID":"/posts/cloud_computing/k8s_practice/deployment-%E5%AE%9E%E8%B7%B5/:2:3","tags":["k8s","云计算"],"title":"Deployment 实践","uri":"/posts/cloud_computing/k8s_practice/deployment-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"2.4 回滚 在错误流程看到，当发布错误的版本后，Deployment 会停止新版本的发布，而这时，就需要通过 kubectl rollout 进行 Deployment 的回滚。 执行 kubectl rollout history，查看每次 Deployment 变更对应的版本。（因为 -record，所有的 kubectl 命令都会被记录）。 可以看到，两次的版本变更都被记录了下来。 通过 –revision 参数，查看对应的命令细节。 通过 kubectl rollout undo 进行版本的回退，默认为上一次版本，通过 –to-revision 可以执行回退的版本。 事实上，回退也是一次“升级”，通过 history 可以看到一个新的部署记录： 这个 4，就是最新的一次回滚执行的命令了。 ","date":"2020-10-16","objectID":"/posts/cloud_computing/k8s_practice/deployment-%E5%AE%9E%E8%B7%B5/:2:4","tags":["k8s","云计算"],"title":"Deployment 实践","uri":"/posts/cloud_computing/k8s_practice/deployment-%E5%AE%9E%E8%B7%B5/"},{"categories":["k8s 实践"],"content":"单机使用虚拟机搭建 k8s 集群","date":"2020-10-15","objectID":"/posts/cloud_computing/k8s_practice/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/","tags":["k8s","云计算"],"title":"虚拟机 k8s 集群搭建","uri":"/posts/cloud_computing/k8s_practice/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["k8s 实践"],"content":"1 虚拟机集群搭建 目标：创建 3 个虚拟机，用作一个 Master Node，两个 Work Node；当然，三个节点处于同一个网段。 具体步骤如下: 构建节点 构建三个虚拟机，基于 centos 7、内存 2 GB，并通过虚拟机复制功能（其实就是 copy 系统盘），完全复制出 Node 1，Node 2，Node 3。 搭建网络 三个节点需要互相访问，所以将其位于 VirtualBox 创建的 Nat网络下，给予每个 Node 静态的 IP（10.0.2.10 - 10.0.2.12），为了方便访问，并设置 ssh 的 DNAT。 设置每个虚拟机网卡加入其创建的 “NodeNatNetwork”。例如： 启动每个虚拟机，设置其 hostname，与网卡静态 IP。例如： 至此，三个虚拟机位于同一个网段，并且能够相互访问；对外，则通过 VirtualBox 的 Nat 网络能够访问。 ","date":"2020-10-15","objectID":"/posts/cloud_computing/k8s_practice/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:1:0","tags":["k8s","云计算"],"title":"虚拟机 k8s 集群搭建","uri":"/posts/cloud_computing/k8s_practice/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["k8s 实践"],"content":"2 部署 K8s 目标：通过 kubeadm 部署整个 k8s，用 Node-1 为 Master 节点，其他为工作节点。 ","date":"2020-10-15","objectID":"/posts/cloud_computing/k8s_practice/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:2:0","tags":["k8s","云计算"],"title":"虚拟机 k8s 集群搭建","uri":"/posts/cloud_computing/k8s_practice/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["k8s 实践"],"content":"2.1 安装 kubeadm、kubelet、kubectl 安装 kubeadm、kubelet、kubectl。这个官方文档写的很详细，见 Installing kubeadm 。 ","date":"2020-10-15","objectID":"/posts/cloud_computing/k8s_practice/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:2:1","tags":["k8s","云计算"],"title":"虚拟机 k8s 集群搭建","uri":"/posts/cloud_computing/k8s_practice/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["k8s 实践"],"content":"2.2 kubeadm init 初始化 Master 节点 Node-1 节点执行 kubeadm init，将其作为 Master 节点初始化。执行成功后，kubeadm 生成了 Kubernetes 组件的各个配置，以及提供服务的各类证书，位于 /etc/kubernetes 目录下: 并且已经以 static pod 的形式启动了：apiserver、controller-manager、etcd、scheduler。 还有最重要的，kubeadm 为集群生成一个【bootstrap token】，需要加入集群的节点都需要通过这个 token 加入。 * 问题 kubeadm 检查 swap 打开着，kubeadm 推荐不使用 swap，通过 swapoff -a 关闭交换区。 kubectl 默认通过 8080 端口访问，无法执行。 设置 kubectl 的配置文件为 kubeadm 生成的 /etc/kubernetes/admin.conf。（其实就是配置公钥，或者将 admin.conf 移动到 ~/.kube/config 文件，作为默认配置。 ","date":"2020-10-15","objectID":"/posts/cloud_computing/k8s_practice/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:2:2","tags":["k8s","云计算"],"title":"虚拟机 k8s 集群搭建","uri":"/posts/cloud_computing/k8s_practice/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["k8s 实践"],"content":"2.3 kubeadm join [token] 设置工作节点 通过 kubead init 最后返回的提示信息，执行对应 kubeadm join 将 Node-1 Node-2 加入到集群中，作为工作节点。 [root@Node-2 kubeadm join 10.0.2.10:6443 --token mahrou.d3uodof21i3d6yxk --discovery-token-ca-cert-hash sha256:21dfe4ef6b3bbd89f803bf44ff6eda587874336d103d0e4a3b --v 5 可以看到，kubelet 启动后就通过 pod 方式启动了本节点上 kube-proxy 容器： * 问题 无法访问到 Node-1 节点，nc ip 失败，但是可以 ping 通。通过在 Node-1 tcpdump 可以抓取到来自 Node-3 的包，因此应该是防火墙的问题，通过 iptables 对 Node-2 Node-3 IP 开放。 kubectl 无法访问问题，与上述问题一致。 ","date":"2020-10-15","objectID":"/posts/cloud_computing/k8s_practice/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:2:3","tags":["k8s","云计算"],"title":"虚拟机 k8s 集群搭建","uri":"/posts/cloud_computing/k8s_practice/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["k8s 实践"],"content":"2.4 结果 目前为止，就完成了集群的搭建，但是 通过 kubectl get nodes，可以看到所有节点都是 NotReady： kubectl describe node node-1 可以看到，原因是因为没有设置正确的 Network Plugin： ","date":"2020-10-15","objectID":"/posts/cloud_computing/k8s_practice/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:2:4","tags":["k8s","云计算"],"title":"虚拟机 k8s 集群搭建","uri":"/posts/cloud_computing/k8s_practice/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["k8s 实践"],"content":"3 部署网络插件 目的：部署网络插件，使各个节点为 Ready 状态，并其内部 Pod 能够相互通信。 以 Weave 部署为例，部署网络插件： kubectl apply -f \"https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\\n')\" 其描述文件中定义所有 Weave 需要的 BAAC 权限组件，以及最重要的网络插件 Pod 对应的 DaemonSet: 应用成功后，可以看到对应的 DaemonSet 就运行起来，并开始给三个 Node 部署 Pod: 在节点上，可以看到 weave-net 对应的 pod ，包括两个容器： ","date":"2020-10-15","objectID":"/posts/cloud_computing/k8s_practice/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:3:0","tags":["k8s","云计算"],"title":"虚拟机 k8s 集群搭建","uri":"/posts/cloud_computing/k8s_practice/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":["k8s 实践"],"content":"4 部署容器存储插件 目的：为了能够让容器使用网络存储，使得容器数据持久化，需要部署存储插件。 以 Rook 项目为例，部署存储插件： $ kubectl apply -f https://raw.githubusercontent.com/rook/rook/master/cluster/exampleskubernetes/ceph/common.yaml $ kubectl apply -f https://raw.githubusercontent.com/rook/rook/master/cluster/exampleskubernetes/ceph/operator.yaml $ kubectl apply -f https://raw.githubusercontent.com/rook/rook/master/cluster/examples/kubernetes/ceph/cluster.yaml 安装成功后，可以看到，rook 有着自己的 namespace，并且已经部署了 DaemonSet： 可以看到，Pod 也部署成功了： ","date":"2020-10-15","objectID":"/posts/cloud_computing/k8s_practice/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/:4:0","tags":["k8s","云计算"],"title":"虚拟机 k8s 集群搭建","uri":"/posts/cloud_computing/k8s_practice/%E8%99%9A%E6%8B%9F%E6%9C%BA-k8s-%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"},{"categories":null,"content":"博客使用 Hugo 框架进行搭建, 主题使用 LoveIt. Logo 由 gopherize.me 生成, 并使用 realfavicongenerator.net 转化. ","date":"2020-10-15","objectID":"/about/:0:0","tags":null,"title":"关于","uri":"/about/"}]